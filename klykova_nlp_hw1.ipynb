{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f2eddc",
   "metadata": {},
   "source": [
    "# Д/З 1: Извлечение ключевых слов\n",
    "### Выполнила Елизавета Клыкова, БКЛ181\n",
    "#### Пункт 1. Создание мини-корпуса (1 балл)\n",
    "*Подготовить мини-корпус (не меньше 4 текстов, примерный общий объём - 3-5 тысяч токенов) с разметкой ключевых слов. Предполагается, что вы найдете источник текстов, в котором уже выделены ключевые слова. Укажите источник корпуса и опишите, в каком виде там были представлены ключевые слова.*\n",
    "\n",
    "Источник корпуса -- новостной сайт [vesti.ru](https://www.vesti.ru/news). Каждая новость имеет поле с тегами (расположено внизу после текста новости). Как правило, теги отражают не только общую тему, но и детали; обычно в их числе содержатся имена собственные, топонимы и т.д., реально встретившиеся в тексте. Таким образом, теги являются именно ключевыми словами, а не просто метками темы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9ae468",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb110658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import nltk\n",
    "import RAKE\n",
    "import yake\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from statistics import mean\n",
    "from summa import keywords\n",
    "from tqdm.auto import tqdm\n",
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "335d2833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_links():\n",
    "    # загружаем страницу\n",
    "    browser = webdriver.Chrome()\n",
    "    page = browser.get('https://www.vesti.ru/news')\n",
    "\n",
    "    # листаем вниз, чтобы прогрузилось больше статей\n",
    "    elem = browser.find_element(By.TAG_NAME, 'body')\n",
    "    for i in range(10):\n",
    "        elem.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    # получаем ссылки на статьи\n",
    "    link_list = browser.find_elements(By.XPATH, \"//div[@class='list__item']/a\")\n",
    "    links = [art.get_attribute('href') for art in link_list]\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "988a33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_info(link):\n",
    "    page = session.get(link).text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    title = soup.find('title').text.strip()\n",
    "    text = soup.find('div', {'class': 'article__text'}).text.strip()\n",
    "\n",
    "    tags = []\n",
    "    tags_list = soup.find('div', {'class': 'tags'}).find_all(\n",
    "        'a', {'class': 'tags__item'})\n",
    "    for t in tags_list:\n",
    "        tag = t.text.strip()\n",
    "        tags.append(tag)\n",
    "\n",
    "    return title, text, ', '.join(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82c2ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_info():\n",
    "    links = get_article_links()\n",
    "    titles, texts, tag_lists = [], [], []\n",
    "\n",
    "    for link in tqdm(links):\n",
    "        title, text, tags = get_article_info(link)\n",
    "        titles.append(title)\n",
    "        texts.append(text)\n",
    "        tag_lists.append(tags)\n",
    "\n",
    "    return links, titles, texts, tag_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2061b7b6",
   "metadata": {},
   "source": [
    "Выкачиваем статьи. Тексты получены за 18:35 3-го ноября 2021 г."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67ab5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_corpus():\n",
    "\n",
    "    # проверяем, существует ли готовый корпус\n",
    "    if os.path.exists('mini_news_corpus.tsv'):\n",
    "        news_df = pd.read_csv('mini_news_corpus.tsv', sep='\\t')\n",
    "\n",
    "    else:\n",
    "        session = requests.session()\n",
    "        links, titles, texts, tag_lists = get_all_info()\n",
    "        clean_texts = [re.sub('((<|&.*?lt;).+?(>|&.*?gt;))', '', text)\n",
    "                       for text in texts]\n",
    "        lengths = [len(t.split()) for t in texts]\n",
    "        news_df = pd.DataFrame({'title': titles,\n",
    "                                'link': links,\n",
    "                                'text': clean_texts,\n",
    "                                'text_len': lengths,\n",
    "                                'auto_tags': tag_lists})\n",
    "        news_df.to_csv('mini_news_corpus.tsv', sep='\\t', index=False)\n",
    "\n",
    "    return news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c36c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = get_news_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32638c73",
   "metadata": {},
   "source": [
    "Проверяем, сколько получилось текстов и какова их суммарная длина."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d2c172a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Всего текстов: 40, общее число токенов: 6698.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = news_df['text_len'].tolist()\n",
    "corpus_stats = 'Всего текстов: {}, общее число токенов: {}.'.format(\n",
    "    len(lengths), sum(lengths))\n",
    "\n",
    "corpus_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524a41b0",
   "metadata": {},
   "source": [
    "Сразу лемматизируем тексты корпуса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4d0030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86415db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text, no_punct=False):\n",
    "\n",
    "    # токенизация nltk (она точнее, чем у пайморфи, и не дробит числа)\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # лемматизация пайморфи\n",
    "    parsed = [m.parse(t)[0] for t in tokens]\n",
    "\n",
    "    # если нужно, убираем пунктуацию\n",
    "    # заодно избавляемся от странных неубиваемых кавычек\n",
    "    if no_punct:\n",
    "        lemmas = [w.normal_form for w in parsed\n",
    "                  if 'PNCT' not in w.tag\n",
    "                  and '``' not in w.normal_form]\n",
    "    else:\n",
    "        lemmas = [w.normal_form for w in parsed if '``' not in w.normal_form]\n",
    "\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36fe50dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = news_df['text'].tolist()\n",
    "lem_texts = [normalize_text(text, no_punct=True) for text in texts]\n",
    "news_df['lem_text'] = lem_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343c2a06",
   "metadata": {},
   "source": [
    "#### Пункт 2. Создание ручной разметки (2 балла)\n",
    "*Разметить ключевые слова самостоятельно. Оценить пересечение с имеющейся разметкой. Составить эталон разметки (например, пересечение или объединение вашей разметки и исходной).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbf3f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manual_tags(news_df):\n",
    "\n",
    "    # если в корпусе еще нет тегов, вводим через инпут\n",
    "    if 'manual_tags' not in news_df.columns:\n",
    "\n",
    "        texts = news_df['text'].tolist()\n",
    "        manual_tag_lists = []\n",
    "        for text in texts:\n",
    "            print('\\n**********\\n\\n', text, '\\n\\n**********\\n')\n",
    "            manual_tags = input('Введите ключевые слова: ')\n",
    "            manual_tag_lists.append(manual_tags)\n",
    "        news_df['manual_tags'] = manual_tag_lists\n",
    "\n",
    "    return news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b79ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = get_manual_tags(news_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db1c9ec",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12983585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходные теги: общество, регионы, выходные, коронавирус, ограничение, пандемия, COVID-19, новости, ГТРК \"Смоленск\"\n",
      "Ручные теги: коронавирус, ограничения, Смоленская область, локдаун, Курская область, Челябинская область, Брянская область, Новгородская область, нерабочие дни, выходные дни \n",
      "\n",
      "Исходные теги: происшествия, самолет, Белоруссия, крушение, Ан-12, Иркутск, новости\n",
      "Ручные теги: крушение самолета, Ан-12, экипаж, ТАСС, Гродно, Иркутск, Пивовариха \n",
      "\n",
      "Исходные теги: происшествия, самолет, ЧП, новости, Новосибирск\n",
      "Ручные теги: Boeing-747, аварийная посадка, самолет, ASL Airlines Belgium \n",
      "\n",
      "Исходные теги: экономика, Германия, Польша, Украина, газ, Северный поток - 2, новости\n",
      "Ручные теги: газ, Газпром, Украина, Европа, Россия, Северный поток-2, Германия, Кублик, экономика \n",
      "\n",
      "Исходные теги: спорт, теннис, Карен Хачанов, новости, ATP-тур теннис\n",
      "Ручные теги: Карен Хачанов, Париж, теннис, турнир, теннисный турнир, Андрей Рублев, Григор Димитров, Александр Зверев, Душан Лайович \n",
      "\n"
     ]
    }
   ],
   "source": [
    "auto_tags = news_df['auto_tags'].tolist()\n",
    "manual_tags = news_df['manual_tags'].tolist()\n",
    "\n",
    "for i, tags in enumerate(auto_tags[0:5]):\n",
    "    print('Исходные теги:', tags)\n",
    "    print('Ручные теги:', manual_tags[i], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6093220",
   "metadata": {},
   "source": [
    "Можно собой гордиться -- получилось довольно точно. В случае с ручными тегами получился уклон в имена собственные, тогда как теги с сайта более общие. Попробуем взять перечение разметок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcbc6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_tgs = [set(tags.split(', ')) for tags in auto_tags]\n",
    "manual_tgs = [set(tags.split(', ')) for tags in manual_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b81e51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['коронавирус']\n",
      "['Иркутск', 'Ан-12']\n",
      "['самолет']\n",
      "['Германия', 'Украина', 'газ', 'экономика']\n",
      "['Карен Хачанов', 'теннис']\n"
     ]
    }
   ],
   "source": [
    "for i, tags in enumerate(auto_tgs[0:5]):\n",
    "    print(list(tags.intersection(manual_tgs[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b274a",
   "metadata": {},
   "source": [
    "Пересения есть почти везде (лишь в 3 случаях из 40 пересечение пустое), но набора общих тегов не всегда достаточно для полноценного представления текста. Посмотрим на объединение разметок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7963a896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COVID-19', 'Брянская область', 'ГТРК \"Смоленск\"', 'Курская область', 'Новгородская область', 'Смоленская область', 'Челябинская область', 'выходные', 'выходные дни', 'коронавирус', 'локдаун', 'нерабочие дни', 'новости', 'общество', 'ограничение', 'ограничения', 'пандемия', 'регионы']\n",
      "['Ан-12', 'Белоруссия', 'Гродно', 'Иркутск', 'Пивовариха', 'ТАСС', 'крушение', 'крушение самолета', 'новости', 'происшествия', 'самолет', 'экипаж']\n",
      "['ASL Airlines Belgium', 'Boeing-747', 'Новосибирск', 'ЧП', 'аварийная посадка', 'новости', 'происшествия', 'самолет']\n",
      "['Газпром', 'Германия', 'Европа', 'Кублик', 'Польша', 'Россия', 'Северный поток - 2', 'Северный поток-2', 'Украина', 'газ', 'новости', 'экономика']\n",
      "['ATP-тур теннис', 'Александр Зверев', 'Андрей Рублев', 'Григор Димитров', 'Душан Лайович', 'Карен Хачанов', 'Париж', 'новости', 'спорт', 'теннис', 'теннисный турнир', 'турнир']\n"
     ]
    }
   ],
   "source": [
    "for i, tags in enumerate(auto_tgs[0:5]):\n",
    "    print(sorted(list(tags.union(manual_tgs[i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a387a567",
   "metadata": {},
   "source": [
    "Получается уже лучше, но есть несколько проблем:\n",
    "\n",
    "1. Число существительных: так, в первом случае встречаются \"ограничения\" и \"ограничение\".\n",
    "2. Повторения: \"Роберт Дауни-мл\" встречается в одном наборе с \"Роберт Дауни-младший\".\n",
    "3. Мусорные теги: во всех наборах есть тег \"новости\". Зачем он, если мы и так знаем, что брали статьи с сайта новостей?\n",
    "4. Мета-теги, которые не встречаются в самих текстах (\"спорт\", \"общество\"). Они могут относительно точно описывать содержание, но у тех алгоритмов, которые мы будем использовать, нет возможности изобрести эти теги, если их нет в текстах.\n",
    "\n",
    "Первую проблему можно решить лемматизацией ключевых слов (тем более, это пригодится для сравнения автоматически выделенных слов и конструкций с эталоном), третью и четвертую -- выбрасыванием тегов, которые не встречаются в соответствующих текстах. Однако и без ручной очистки не обойтись."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea2f5058",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_union = [tags.union(manual_tgs[i])\n",
    "              for i, tags in enumerate(auto_tgs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28878015",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tags = []\n",
    "\n",
    "for tagset, text in list(zip(tags_union, lem_texts)):\n",
    "    clean_tagset = []\n",
    "    for tag in tagset:\n",
    "        # лемматизируем, убирая пунктуацию\n",
    "        lem_tag = normalize_text(tag, no_punct=True)\n",
    "        # часть тегов заменяем (в текущем виде они не встречаются в текстах)\n",
    "        clean_tag = lem_tag.replace(\n",
    "                'atp-тур теннис', 'atp').replace(\n",
    "                'wta-тур теннис', 'wta').replace(\n",
    "                'сша/америка', 'америка').replace(\n",
    "                'машина/автомобиль', 'автомобиль').replace(\n",
    "                'смерть/кончин', 'смерть').replace(\n",
    "                'александр звереть', 'александр зверев').replace(\n",
    "                'министерство финансов/минфин', 'министерство финансов')\n",
    "        # выбрасываем то, чего нет в тексте\n",
    "        # в основном мета-теги \"новости\", \"общество\", \"спорт\"\n",
    "        if clean_tag in text:\n",
    "            clean_tagset.append(clean_tag)\n",
    "\n",
    "    # убираем повторения, появившиеся после лемматизации\n",
    "    final_tags.append(set(clean_tagset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2404dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tags_str = [', '.join(tags) for tags in final_tags]\n",
    "news_df['gold_tags'] = final_tags_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1f4ecb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "локдаун, курский область, смоленский область, новгородский область, выходной, коронавирус, нерабочий день, регион, брянский область, выходной день, челябинский область\n",
      "крушение самолёт, экипаж, пивовариха, самолёт, иркутск, ан-12, гродно, тасс, крушение\n",
      "asl airlines belgium, новосибирск, самолёт, аварийный посадка, boeing-747\n",
      "газ, германия, кублик, европа, экономика, россия, газпром, северный поток-2, украина\n",
      "александр зверев, андрей рублёв, турнир, григор димитров, теннис, душан лайович, париж, карен хачан, теннисный турнир\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(final_tags_str[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee7dece8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>text_len</th>\n",
       "      <th>lem_text</th>\n",
       "      <th>auto_tags</th>\n",
       "      <th>manual_tags</th>\n",
       "      <th>gold_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Пять регионов в борьбе с COVID-19 продлили нер...</td>\n",
       "      <td>https://www.vesti.ru/article/2634849</td>\n",
       "      <td>В ряде российских регионов для сдерживания рас...</td>\n",
       "      <td>166</td>\n",
       "      <td>в ряд российский регион для сдерживание распро...</td>\n",
       "      <td>общество, регионы, выходные, коронавирус, огра...</td>\n",
       "      <td>коронавирус, ограничения, Смоленская область, ...</td>\n",
       "      <td>локдаун, курский область, смоленский область, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Крушение Ан-12 будет расследовать МАК</td>\n",
       "      <td>https://www.vesti.ru/article/2634804</td>\n",
       "      <td>Расследованием крушения самолета Ан-12 займетс...</td>\n",
       "      <td>79</td>\n",
       "      <td>расследование крушение самолёт ан-12 заняться ...</td>\n",
       "      <td>происшествия, самолет, Белоруссия, крушение, А...</td>\n",
       "      <td>крушение самолета, Ан-12, экипаж, ТАСС, Гродно...</td>\n",
       "      <td>крушение самолёт, экипаж, пивовариха, самолёт,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В новосибирском Толмачево совершил экстренную ...</td>\n",
       "      <td>https://www.vesti.ru/article/2634873</td>\n",
       "      <td>Летевший из Бельгии в Китай грузовой Boeing-74...</td>\n",
       "      <td>44</td>\n",
       "      <td>лететь из бельгия в китай грузовой boeing-747 ...</td>\n",
       "      <td>происшествия, самолет, ЧП, новости, Новосибирск</td>\n",
       "      <td>Boeing-747, аварийная посадка, самолет, ASL Ai...</td>\n",
       "      <td>asl airlines belgium, новосибирск, самолёт, ав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>СМИ Польши: Россия не заинтересована в \"Северн...</td>\n",
       "      <td>https://www.vesti.ru/finance/article/2634889</td>\n",
       "      <td>Прокачка российского газа по трубопроводу \"Яма...</td>\n",
       "      <td>163</td>\n",
       "      <td>прокачка российский газ по трубопровод ямал ев...</td>\n",
       "      <td>экономика, Германия, Польша, Украина, газ, Сев...</td>\n",
       "      <td>газ, Газпром, Украина, Европа, Россия, Северны...</td>\n",
       "      <td>газ, германия, кублик, европа, экономика, росс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Для Хачанова турнир в Париже закончен</td>\n",
       "      <td>https://www.vesti.ru/article/2634853</td>\n",
       "      <td>Карен Хачанов не смог выйти в третий круг прох...</td>\n",
       "      <td>91</td>\n",
       "      <td>карен хачан не смочь выйти в третий круг прохо...</td>\n",
       "      <td>спорт, теннис, Карен Хачанов, новости, ATP-тур...</td>\n",
       "      <td>Карен Хачанов, Париж, теннис, турнир, теннисны...</td>\n",
       "      <td>александр зверев, андрей рублёв, турнир, григо...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Пять регионов в борьбе с COVID-19 продлили нер...   \n",
       "1              Крушение Ан-12 будет расследовать МАК   \n",
       "2  В новосибирском Толмачево совершил экстренную ...   \n",
       "3  СМИ Польши: Россия не заинтересована в \"Северн...   \n",
       "4              Для Хачанова турнир в Париже закончен   \n",
       "\n",
       "                                           link  \\\n",
       "0          https://www.vesti.ru/article/2634849   \n",
       "1          https://www.vesti.ru/article/2634804   \n",
       "2          https://www.vesti.ru/article/2634873   \n",
       "3  https://www.vesti.ru/finance/article/2634889   \n",
       "4          https://www.vesti.ru/article/2634853   \n",
       "\n",
       "                                                text  text_len  \\\n",
       "0  В ряде российских регионов для сдерживания рас...       166   \n",
       "1  Расследованием крушения самолета Ан-12 займетс...        79   \n",
       "2  Летевший из Бельгии в Китай грузовой Boeing-74...        44   \n",
       "3  Прокачка российского газа по трубопроводу \"Яма...       163   \n",
       "4  Карен Хачанов не смог выйти в третий круг прох...        91   \n",
       "\n",
       "                                            lem_text  \\\n",
       "0  в ряд российский регион для сдерживание распро...   \n",
       "1  расследование крушение самолёт ан-12 заняться ...   \n",
       "2  лететь из бельгия в китай грузовой boeing-747 ...   \n",
       "3  прокачка российский газ по трубопровод ямал ев...   \n",
       "4  карен хачан не смочь выйти в третий круг прохо...   \n",
       "\n",
       "                                           auto_tags  \\\n",
       "0  общество, регионы, выходные, коронавирус, огра...   \n",
       "1  происшествия, самолет, Белоруссия, крушение, А...   \n",
       "2    происшествия, самолет, ЧП, новости, Новосибирск   \n",
       "3  экономика, Германия, Польша, Украина, газ, Сев...   \n",
       "4  спорт, теннис, Карен Хачанов, новости, ATP-тур...   \n",
       "\n",
       "                                         manual_tags  \\\n",
       "0  коронавирус, ограничения, Смоленская область, ...   \n",
       "1  крушение самолета, Ан-12, экипаж, ТАСС, Гродно...   \n",
       "2  Boeing-747, аварийная посадка, самолет, ASL Ai...   \n",
       "3  газ, Газпром, Украина, Европа, Россия, Северны...   \n",
       "4  Карен Хачанов, Париж, теннис, турнир, теннисны...   \n",
       "\n",
       "                                           gold_tags  \n",
       "0  локдаун, курский область, смоленский область, ...  \n",
       "1  крушение самолёт, экипаж, пивовариха, самолёт,...  \n",
       "2  asl airlines belgium, новосибирск, самолёт, ав...  \n",
       "3  газ, германия, кублик, европа, экономика, росс...  \n",
       "4  александр зверев, андрей рублёв, турнир, григо...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d40f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.to_csv('mini_news_corpus.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b63af",
   "metadata": {},
   "source": [
    "#### Пункт 3. Извлечение ключевых слов (2 балла)\n",
    "*Применить к этому корпусу 3 метода извлечения ключевых слов на выбор (RAKE, TextRank, tf-idf, OKAPI BM25, ...).*\n",
    "\n",
    "#### RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38f037fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('russian')\n",
    "rake = RAKE.Rake(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02e8acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# тексты короткие --> minFrequency=1\n",
    "# в эталоне есть конструкции из 3 слов --> maxWords=3\n",
    "rake_kws = []\n",
    "for text in lem_texts:\n",
    "    kw_list = rake.run(text, maxWords=3, minFrequency=1)\n",
    "    rake_kws.append(kw_list)\n",
    "\n",
    "# обрезаем словосочетания с нулевой значимостью\n",
    "rake_nonzero = [[kw for kw in kw_list if kw[-1] > 0] for kw_list in rake_kws]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7febf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('сохранение заработный плата', 9.0),\n",
       " ('удалённый формат взаимодействие', 9.0),\n",
       " ('глава курский область', 8.666666666666666),\n",
       " ('выходной день продлиться', 8.666666666666666),\n",
       " ('челябинский область отмечаться', 8.666666666666666),\n",
       " ('ряд российский регион', 8.0),\n",
       " ('регион нерабочий день', 7.166666666666666),\n",
       " ('нерабочий день', 5.166666666666666),\n",
       " ('новгородский область', 4.666666666666666),\n",
       " ('7 ноябрь ранее', 4.0),\n",
       " ('12 ноябрь включительно', 4.0),\n",
       " ('14 ноябрь включительно', 4.0),\n",
       " ('15 ноябрь кроме', 4.0),\n",
       " ('15 ноябрь продлить', 4.0),\n",
       " ('регион', 2.0),\n",
       " ('продление', 1.0),\n",
       " ('внести', 1.0),\n",
       " ('указ', 1.0),\n",
       " ('ввести', 1.0),\n",
       " ('28 октябрь', 1.0),\n",
       " ('неделя', 1.0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rake_nonzero[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30912215",
   "metadata": {},
   "source": [
    "#### TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12a67eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "textrank_kws = []\n",
    "for text in lem_texts:\n",
    "    kw_list = keywords.keywords(text, language='russian', ratio=0.15,\n",
    "                                additional_stopwords=stop, scores=True)\n",
    "    textrank_kws.append(kw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2cf2b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('область', 0.45644809380680473),\n",
       " ('продлиться', 0.2678215545264045),\n",
       " ('продлить режим', 0.2557232425480802),\n",
       " ('регион', 0.24197844692997414),\n",
       " ('ноябрь', 0.21250773634791137),\n",
       " ('власть', 0.17828231380378326),\n",
       " ('день', 0.1674290010638988),\n",
       " ('заработный', 0.15333775933879376),\n",
       " ('формат', 0.15333775933879362)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textrank_kws[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86f7614",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ca67012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# векторизуем, выбрасывая стоп-слова и используя n-граммы\n",
    "vectorizer = TfidfVectorizer(stop_words=stop, ngram_range=(1, 3))\n",
    "vectors = vectorizer.fit_transform(lem_texts)\n",
    "\n",
    "data = vectors.toarray()\n",
    "words = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "241de063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# возьмем столько слов/n-грамм, сколько максимально бывает в эталоне\n",
    "gold_kws_lem = [taglist.split(', ')\n",
    "                for taglist in news_df['gold_tags'].tolist()]\n",
    "n_max = max([len(i) for i in gold_kws_lem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbb613bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_kws = []\n",
    "\n",
    "for doc in data:\n",
    "    # сортируем индексы по убыванию значений\n",
    "    sorted_row_idx = np.argsort(doc)[::-1][0:n_max]\n",
    "    # получаем слова и n-граммы с такими индексами\n",
    "    keywords = words[sorted_row_idx.ravel()]\n",
    "    # получаем соответствующие значения\n",
    "    kw_scores = doc[sorted_row_idx.ravel()]\n",
    "    kw_with_scores = tuple(zip(keywords, kw_scores))\n",
    "    tfidf_kws.append(kw_with_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7507abd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('нерабочий день', 0.2268795842568122),\n",
       " ('нерабочий', 0.2268795842568122),\n",
       " ('область', 0.2201740825189737),\n",
       " ('продлить', 0.20541331485732175),\n",
       " ('день', 0.18860865958395617),\n",
       " ('регион', 0.17961543678565908),\n",
       " ('режим', 0.16602652529802747),\n",
       " ('ноябрь', 0.15954403025705216),\n",
       " ('продлить режим нерабочий', 0.1370718658639827),\n",
       " ('продлить режим', 0.1370718658639827),\n",
       " ('режим нерабочий день', 0.12324798891439306),\n",
       " ('режим нерабочий', 0.12324798891439306),\n",
       " ('включительно', 0.1134397921284061))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_kws[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f7c62e",
   "metadata": {},
   "source": [
    "#### YAKE\n",
    "С YAKE у меня возникли некоторые проблемы: во-первых, если задать максимальный размер n-грамм = 3 и число выдаваемых слов = n_max (максимальное число слов в эталоне, у меня 13), то в выдаче всегда будут только сочетания из трех слов. Во-вторых, я вообще не понимаю, как работает параметр top))) потому что если задать top=30, в выдаче будет меньше 30 слов, зато размер n-грамм начнет варьироваться. Оставляю top=30, результат вроде бы выглядит адекватно. (Из-за неполного понимания работы алгоритма я решила, что лучше сделаю его четвертым в списке.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7524f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n -- максимальный размер n-грамм\n",
    "# top -- число выделяемых слов (по идее, но на самом деле лотерея)\n",
    "# dedupLim -- ограничение на дублирование слов в выдаче\n",
    "# стоп-слова выбрасываются дефолтно и берутся из NLTK для указанного языка\n",
    "\n",
    "yake_extractor = yake.KeywordExtractor(lan='ru', n=3,\n",
    "                                       dedupLim=0.2, top=30, features=None)\n",
    "yake_kws = []\n",
    "\n",
    "for text in lem_texts:\n",
    "    yake_kws.append(yake_extractor.extract_keywords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7999915e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('продлить режим нерабочий', 0.0003236931906584315),\n",
       " ('островский подписать указ', 0.0009880119291171172),\n",
       " ('режим повышенный готовность', 0.0010022151249883932),\n",
       " ('ужесточать ограничительный мера', 0.0010159615912341729),\n",
       " ('высокий учебный заведение', 0.0010159615912341729),\n",
       " ('область губернатор регион', 0.002932689491805779),\n",
       " ('ноябрь', 0.009997807124087998),\n",
       " ('коронавирус ужесточать', 0.010017448676415503),\n",
       " ('ранее локдаун', 0.011405247838416658),\n",
       " ('указ', 0.048448977173929195),\n",
       " ('выходной', 0.048448977173929195),\n",
       " ('власть', 0.05661550740051128),\n",
       " ('ряд', 0.09958963134819915),\n",
       " ('мера', 0.09958963134819915),\n",
       " ('учиться', 0.09958963134819915),\n",
       " ('решение', 0.09958963134819915),\n",
       " ('жвачкина', 0.09958963134819915)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# скоры обратно пропорциональны значимости\n",
    "yake_kws[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7131fb45",
   "metadata": {},
   "source": [
    "#### Пункт 4. Составление шаблонов для ключевых слов (2 балла)\n",
    "*Составить морфологические/синтаксические шаблоны для ключевых слов и фраз, выделить соответствующие им подстроки из корпуса (например, именные группы Adj+Noun). Применить эти фильтры к спискам ключевых слов.*\n",
    "\n",
    "Какая информация вообще бывает?\n",
    "* часть речи -- точно нужно использовать в шаблонах\n",
    "* падеж и число -- пропадают при лемматизации, не помогут\n",
    "* род -- пропадает у всего, кроме существительных, а для существительных это вряд ли важный критерий (было бы контринтуитивно считать, что сущ. м. р. чаще бывают ключевыми, чем сущ. ж. р.)\n",
    "* одушевленность -- имеет смысл использовать, может быть важно\n",
    "* вид и переходность глаголов -- не похоже, что должны влиять (можно поэкспериментировать, но мне лень)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "098fec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pattern_with_pos(tag):\n",
    "    tag_pattern = []\n",
    "    tag_parts = tag.split()\n",
    "    for part in tag_parts:\n",
    "        analysis = m.parse(part)[0].tag\n",
    "        pos = analysis.POS\n",
    "        if pos:\n",
    "            tag_pattern.append(pos)\n",
    "        # не теряем числа\n",
    "        elif 'NUMB' in analysis:\n",
    "            tag_pattern.append('NUMB')\n",
    "        # учитываем иностранные названия\n",
    "        elif 'LATN' in analysis:\n",
    "            tag_pattern.append('LATN')\n",
    "    return ' + '.join(tag_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7844b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pattern_with_animacy(tag):\n",
    "    tag_pattern = []\n",
    "    tag_parts = tag.split()\n",
    "    for part in tag_parts:\n",
    "        analysis = m.parse(part)[0].tag\n",
    "        pos = analysis.POS\n",
    "        if pos:\n",
    "            if pos == 'NOUN':\n",
    "                anim = analysis.animacy\n",
    "                pos = pos + ',' + anim\n",
    "            tag_pattern.append(pos)\n",
    "        # не теряем числа\n",
    "        elif 'NUMB' in analysis:\n",
    "            tag_pattern.append('NUMB')\n",
    "        # учитываем иностранные названия\n",
    "        elif 'LATN' in analysis:\n",
    "            tag_pattern.append('LATN')\n",
    "    return ' + '.join(tag_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4079a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_tags = [tgs.split(', ') for tgs in news_df['gold_tags'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90e4703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_patterns, animacy_patterns = [], []\n",
    "for tagset in gold_tags:\n",
    "    for tag in tagset:\n",
    "        pos_patterns.append(get_pattern_with_pos(tag))\n",
    "        animacy_patterns.append(get_pattern_with_animacy(tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca84d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_patterns = set(pos_patterns)\n",
    "pos_patterns.remove('')\n",
    "animacy_patterns = set(animacy_patterns)\n",
    "animacy_patterns.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22daeda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJF',\n",
       " 'ADJF + ADJF + NOUN',\n",
       " 'ADJF + NOUN',\n",
       " 'ADJF + NOUN + NOUN',\n",
       " 'ADJF + NOUN + NOUN + NOUN',\n",
       " 'INFN',\n",
       " 'LATN',\n",
       " 'LATN + LATN',\n",
       " 'LATN + LATN + LATN',\n",
       " 'NOUN',\n",
       " 'NOUN + ADJF',\n",
       " 'NOUN + ADJF + NOUN',\n",
       " 'NOUN + GRND',\n",
       " 'NOUN + NOUN',\n",
       " 'NOUN + NOUN + NOUN + NOUN',\n",
       " 'NOUN + NUMB'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6706fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJF',\n",
       " 'ADJF + ADJF + NOUN,inan',\n",
       " 'ADJF + NOUN,inan',\n",
       " 'ADJF + NOUN,inan + NOUN,inan',\n",
       " 'ADJF + NOUN,inan + NOUN,inan + NOUN,inan',\n",
       " 'INFN',\n",
       " 'LATN',\n",
       " 'LATN + LATN',\n",
       " 'LATN + LATN + LATN',\n",
       " 'NOUN,anim',\n",
       " 'NOUN,anim + ADJF',\n",
       " 'NOUN,anim + GRND',\n",
       " 'NOUN,anim + NOUN,anim',\n",
       " 'NOUN,anim + NOUN,inan',\n",
       " 'NOUN,inan',\n",
       " 'NOUN,inan + ADJF + NOUN,inan',\n",
       " 'NOUN,inan + NOUN,anim',\n",
       " 'NOUN,inan + NOUN,anim + NOUN,anim + NOUN,anim',\n",
       " 'NOUN,inan + NOUN,inan',\n",
       " 'NOUN,inan + NUMB'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animacy_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e60c1a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_kws_without_scores(kws_with_scores):\n",
    "    kws_without_scores = []\n",
    "    for kw_set in kws_with_scores:\n",
    "        kws_without_scores.append([kw[0] for kw in kw_set])\n",
    "    return kws_without_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23829770",
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_full = get_kws_without_scores(rake_nonzero)\n",
    "textrank_full = get_kws_without_scores(textrank_kws)\n",
    "tfidf_full = get_kws_without_scores(tfidf_kws)\n",
    "yake_full = get_kws_without_scores(yake_kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0e2ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_keywords_with_pos(keywords, patterns):\n",
    "    filtered_kws = []\n",
    "    for kw in keywords:\n",
    "        kw_pattern = get_pattern_with_pos(kw)\n",
    "        if kw_pattern in patterns:\n",
    "            filtered_kws.append(kw)\n",
    "    return filtered_kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "670f7c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_all_with_pos(kw_lists, patterns):\n",
    "    filtered_kw_lists = []\n",
    "    for kw_list in kw_lists:\n",
    "        filtered_kw_lists.append(\n",
    "            filter_keywords_with_pos(kw_list, patterns))\n",
    "    return filtered_kw_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c60d6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_keywords_with_animacy(keywords, patterns):\n",
    "    filtered_kws = []\n",
    "    for kw in keywords:\n",
    "        kw_pattern = get_pattern_with_animacy(kw)\n",
    "        if kw_pattern in patterns:\n",
    "            filtered_kws.append(kw)\n",
    "    return filtered_kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1fdea465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_all_with_animacy(kw_lists, patterns):\n",
    "    filtered_kw_lists = []\n",
    "    for kw_list in kw_lists:\n",
    "        filtered_kw_lists.append(\n",
    "            filter_keywords_with_animacy(kw_list, patterns))\n",
    "    return filtered_kw_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3b114f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_with_pos = filter_all_with_pos(rake_full, pos_patterns)\n",
    "textrank_with_pos = filter_all_with_pos(textrank_full, pos_patterns)\n",
    "tfidf_with_pos = filter_all_with_pos(tfidf_full, pos_patterns)\n",
    "yake_with_pos = filter_all_with_pos(yake_full, pos_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "08399455",
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_with_animacy = filter_all_with_animacy(rake_full, animacy_patterns)\n",
    "textrank_with_animacy = filter_all_with_animacy(textrank_full,\n",
    "                                                animacy_patterns)\n",
    "tfidf_with_animacy = filter_all_with_animacy(tfidf_full, animacy_patterns)\n",
    "yake_with_animacy = filter_all_with_animacy(yake_full, animacy_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e440484",
   "metadata": {},
   "source": [
    "Выдача в целом похожая, не буду печатать, потому что там очень много. На результаты фильтрации с использованием части речи + одушевленности можно посмотреть в разделе 6 ниже.\n",
    "\n",
    "#### Пункт 5. Оценка выделения ключевых слов (2 балла)\n",
    "*Оценить точность, полноту, F-меру выбранных методов относительно эталона: с учётом морфосинтаксических шаблонов и без них.*\n",
    "\n",
    "Приведем оценки для всех трех типов методов: без фильтрации, с фильтрацией только по частям речи и с фильтрацией по частям речи + одушевленности существительных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d0c1f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_set(gold, predicted):\n",
    "    # у новости про Моргенштерна после фильтрации не осталось тегов\n",
    "    if len(predicted) == 0:\n",
    "        return 0, 0, 0\n",
    "\n",
    "    gold = set(gold)\n",
    "    predicted = set(predicted)\n",
    "    precision = len(gold.intersection(predicted)) / len(predicted)\n",
    "    recall = len(gold.intersection(predicted)) / len(gold)\n",
    "    f1 = 0\n",
    "    if precision + recall != 0:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "083be2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all(gold_lists, predicted_lists):\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "\n",
    "    for pair in list(zip(gold_lists, predicted_lists)):\n",
    "        precision, recall, f1 = evaluate_set(pair[0], pair[1])\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    return [round(mean(precisions), 3),\n",
    "            round(mean(recalls), 3),\n",
    "            round(mean(f1s), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f15e8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'method': ['precision', 'recall', 'f1-score'],\n",
    "           'RAKE_full': evaluate_all(gold_tags, rake_full),\n",
    "           'RAKE_pos': evaluate_all(gold_tags, rake_with_pos),\n",
    "           'RAKE_anim': evaluate_all(gold_tags, rake_with_animacy),\n",
    "           'textrank_full': evaluate_all(gold_tags, textrank_full),\n",
    "           'textrank_pos': evaluate_all(gold_tags, textrank_with_pos),\n",
    "           'textrank_anim': evaluate_all(gold_tags, textrank_with_animacy),\n",
    "           'tfidf_full': evaluate_all(gold_tags, tfidf_full),\n",
    "           'tfidf_pos': evaluate_all(gold_tags, tfidf_with_pos),\n",
    "           'tfidf_anim': evaluate_all(gold_tags, tfidf_with_animacy),\n",
    "           'yake_full': evaluate_all(gold_tags, yake_full),\n",
    "           'yake_pos': evaluate_all(gold_tags, yake_with_pos),\n",
    "           'yake_anim': evaluate_all(gold_tags, yake_with_animacy),\n",
    "           }\n",
    "\n",
    "scores_df = pd.DataFrame(metrics).set_index('method').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7fc62f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c144f_row0_col0, #T_c144f_row0_col2, #T_c144f_row3_col1, #T_c144f_row4_col1, #T_c144f_row5_col1 {\n",
       "  background-color: lightsalmon;\n",
       "}\n",
       "#T_c144f_row6_col1, #T_c144f_row7_col1, #T_c144f_row8_col0, #T_c144f_row8_col1, #T_c144f_row8_col2 {\n",
       "  background-color: palegreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c144f_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >method</th>\n",
       "      <th class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th class=\"col_heading level0 col2\" >f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c144f_level0_row0\" class=\"row_heading level0 row0\" >RAKE_full</th>\n",
       "      <td id=\"T_c144f_row0_col0\" class=\"data row0 col0\" >0.063</td>\n",
       "      <td id=\"T_c144f_row0_col1\" class=\"data row0 col1\" >0.151</td>\n",
       "      <td id=\"T_c144f_row0_col2\" class=\"data row0 col2\" >0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c144f_level0_row1\" class=\"row_heading level0 row1\" >RAKE_pos</th>\n",
       "      <td id=\"T_c144f_row1_col0\" class=\"data row1 col0\" >0.113</td>\n",
       "      <td id=\"T_c144f_row1_col1\" class=\"data row1 col1\" >0.148</td>\n",
       "      <td id=\"T_c144f_row1_col2\" class=\"data row1 col2\" >0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c144f_level0_row2\" class=\"row_heading level0 row2\" >RAKE_anim</th>\n",
       "      <td id=\"T_c144f_row2_col0\" class=\"data row2 col0\" >0.117</td>\n",
       "      <td id=\"T_c144f_row2_col1\" class=\"data row2 col1\" >0.148</td>\n",
       "      <td id=\"T_c144f_row2_col2\" class=\"data row2 col2\" >0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c144f_level0_row3\" class=\"row_heading level0 row3\" >textrank_full</th>\n",
       "      <td id=\"T_c144f_row3_col0\" class=\"data row3 col0\" >0.100</td>\n",
       "      <td id=\"T_c144f_row3_col1\" class=\"data row3 col1\" >0.128</td>\n",
       "      <td id=\"T_c144f_row3_col2\" class=\"data row3 col2\" >0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c144f_level0_row4\" class=\"row_heading level0 row4\" >textrank_pos</th>\n",
       "      <td id=\"T_c144f_row4_col0\" class=\"data row4 col0\" >0.116</td>\n",
       "      <td id=\"T_c144f_row4_col1\" class=\"data row4 col1\" >0.128</td>\n",
       "      <td id=\"T_c144f_row4_col2\" class=\"data row4 col2\" >0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c144f_level0_row5\" class=\"row_heading level0 row5\" >textrank_anim</th>\n",
       "      <td id=\"T_c144f_row5_col0\" class=\"data row5 col0\" >0.118</td>\n",
       "      <td id=\"T_c144f_row5_col1\" class=\"data row5 col1\" >0.128</td>\n",
       "      <td id=\"T_c144f_row5_col2\" class=\"data row5 col2\" >0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c144f_level0_row6\" class=\"row_heading level0 row6\" >tfidf_full</th>\n",
       "      <td id=\"T_c144f_row6_col0\" class=\"data row6 col0\" >0.188</td>\n",
       "      <td id=\"T_c144f_row6_col1\" class=\"data row6 col1\" >0.327</td>\n",
       "      <td id=\"T_c144f_row6_col2\" class=\"data row6 col2\" >0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c144f_level0_row7\" class=\"row_heading level0 row7\" >tfidf_pos</th>\n",
       "      <td id=\"T_c144f_row7_col0\" class=\"data row7 col0\" >0.237</td>\n",
       "      <td id=\"T_c144f_row7_col1\" class=\"data row7 col1\" >0.327</td>\n",
       "      <td id=\"T_c144f_row7_col2\" class=\"data row7 col2\" >0.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c144f_level0_row8\" class=\"row_heading level0 row8\" >tfidf_anim</th>\n",
       "      <td id=\"T_c144f_row8_col0\" class=\"data row8 col0\" >0.240</td>\n",
       "      <td id=\"T_c144f_row8_col1\" class=\"data row8 col1\" >0.327</td>\n",
       "      <td id=\"T_c144f_row8_col2\" class=\"data row8 col2\" >0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c144f_level0_row9\" class=\"row_heading level0 row9\" >yake_full</th>\n",
       "      <td id=\"T_c144f_row9_col0\" class=\"data row9 col0\" >0.065</td>\n",
       "      <td id=\"T_c144f_row9_col1\" class=\"data row9 col1\" >0.148</td>\n",
       "      <td id=\"T_c144f_row9_col2\" class=\"data row9 col2\" >0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c144f_level0_row10\" class=\"row_heading level0 row10\" >yake_pos</th>\n",
       "      <td id=\"T_c144f_row10_col0\" class=\"data row10 col0\" >0.108</td>\n",
       "      <td id=\"T_c144f_row10_col1\" class=\"data row10 col1\" >0.148</td>\n",
       "      <td id=\"T_c144f_row10_col2\" class=\"data row10 col2\" >0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c144f_level0_row11\" class=\"row_heading level0 row11\" >yake_anim</th>\n",
       "      <td id=\"T_c144f_row11_col0\" class=\"data row11 col0\" >0.114</td>\n",
       "      <td id=\"T_c144f_row11_col1\" class=\"data row11 col1\" >0.148</td>\n",
       "      <td id=\"T_c144f_row11_col2\" class=\"data row11 col2\" >0.126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2061b2fb520>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.style.highlight_max(\n",
    "    color='palegreen', axis=0).highlight_min(\n",
    "    color='lightsalmon', axis=0).format('{:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bfadc7",
   "metadata": {},
   "source": [
    "Мы видим, что наиболее точным оказался метод TF-IDF, наименее точным -- RAKE (но его различия с YAKE и TextRank не очень большие). Однако к результатам следует относиться с некоторой осторожностью. Во-первых, нужно понимать, что в случае с TF-IDF у нас была возможность выбрать параметры: сколько ключевых слов возвращать, что использовать при выделении ключевых слов (только слова / би-граммы / три-граммы). И если для RAKE существует по крайней мере возможность задать лимит по числу слов в конструкции, то TextRank это число определяет сам (поэтому в итоговом наборе есть конструкции из 4-5 слов). Аналогично, для TF-IDF количество ключевых слов и конструкций было жестко задано как максимальное число тегов в эталоне для одного текста, RAKE выбирал это число сам, а для TextRank была задана доля слов, которые можно выбрать как ключевые (т.е. число ключевых слов зависело от объема текста, а объем варьируется, что видно из датафрейма; при этом в эталоне такого разнообразия нет). Что касается YAKE, там вообще все плохо, начиная от несоответствия числа слов в выдаче заданному параметру top и заканчивая тем, что параметр top каким-то неочевидным способом влияет на число слов в ключевых конструкциях (???).\n",
    "\n",
    "Заметно, что использование шаблонов улучшило метрики (причем более подробные шаблоны повлияли на качество сильнее, чем шаблоны, использующие только информацию о частях речи). Интересно, что влияние шаблонов вообще отсутствует в случае с YAKE (видимо, ему уже ничто не поможет))).\n",
    "\n",
    "Посмотрим внимательнее на лучшие и худшие результаты в рамках отдельных методов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50e0e914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e9581_row0_col0, #T_e9581_row0_col2, #T_e9581_row1_col1, #T_e9581_row2_col1 {\n",
       "  background-color: lightsalmon;\n",
       "}\n",
       "#T_e9581_row0_col1, #T_e9581_row2_col0, #T_e9581_row2_col2 {\n",
       "  background-color: palegreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e9581_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >method</th>\n",
       "      <th class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th class=\"col_heading level0 col2\" >f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e9581_level0_row0\" class=\"row_heading level0 row0\" >RAKE_full</th>\n",
       "      <td id=\"T_e9581_row0_col0\" class=\"data row0 col0\" >0.063</td>\n",
       "      <td id=\"T_e9581_row0_col1\" class=\"data row0 col1\" >0.151</td>\n",
       "      <td id=\"T_e9581_row0_col2\" class=\"data row0 col2\" >0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9581_level0_row1\" class=\"row_heading level0 row1\" >RAKE_pos</th>\n",
       "      <td id=\"T_e9581_row1_col0\" class=\"data row1 col0\" >0.113</td>\n",
       "      <td id=\"T_e9581_row1_col1\" class=\"data row1 col1\" >0.148</td>\n",
       "      <td id=\"T_e9581_row1_col2\" class=\"data row1 col2\" >0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e9581_level0_row2\" class=\"row_heading level0 row2\" >RAKE_anim</th>\n",
       "      <td id=\"T_e9581_row2_col0\" class=\"data row2 col0\" >0.117</td>\n",
       "      <td id=\"T_e9581_row2_col1\" class=\"data row2 col1\" >0.148</td>\n",
       "      <td id=\"T_e9581_row2_col2\" class=\"data row2 col2\" >0.118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2062068afa0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rake_df = scores_df[0:3]\n",
    "rake_df.style.highlight_max(\n",
    "    color='palegreen', axis=0).highlight_min(\n",
    "    color='lightsalmon', axis=0).format('{:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da575a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0816b_row0_col0, #T_0816b_row0_col2 {\n",
       "  background-color: lightsalmon;\n",
       "}\n",
       "#T_0816b_row0_col1, #T_0816b_row1_col1, #T_0816b_row2_col1 {\n",
       "  background-color: palegreen;\n",
       "  background-color: lightsalmon;\n",
       "}\n",
       "#T_0816b_row1_col2, #T_0816b_row2_col0, #T_0816b_row2_col2 {\n",
       "  background-color: palegreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0816b_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >method</th>\n",
       "      <th class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th class=\"col_heading level0 col2\" >f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0816b_level0_row0\" class=\"row_heading level0 row0\" >textrank_full</th>\n",
       "      <td id=\"T_0816b_row0_col0\" class=\"data row0 col0\" >0.100</td>\n",
       "      <td id=\"T_0816b_row0_col1\" class=\"data row0 col1\" >0.128</td>\n",
       "      <td id=\"T_0816b_row0_col2\" class=\"data row0 col2\" >0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0816b_level0_row1\" class=\"row_heading level0 row1\" >textrank_pos</th>\n",
       "      <td id=\"T_0816b_row1_col0\" class=\"data row1 col0\" >0.116</td>\n",
       "      <td id=\"T_0816b_row1_col1\" class=\"data row1 col1\" >0.128</td>\n",
       "      <td id=\"T_0816b_row1_col2\" class=\"data row1 col2\" >0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0816b_level0_row2\" class=\"row_heading level0 row2\" >textrank_anim</th>\n",
       "      <td id=\"T_0816b_row2_col0\" class=\"data row2 col0\" >0.118</td>\n",
       "      <td id=\"T_0816b_row2_col1\" class=\"data row2 col1\" >0.128</td>\n",
       "      <td id=\"T_0816b_row2_col2\" class=\"data row2 col2\" >0.115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2062068a130>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textrank_df = scores_df[3:6]\n",
    "textrank_df.style.highlight_max(\n",
    "    color='palegreen', axis=0).highlight_min(\n",
    "    color='lightsalmon', axis=0).format('{:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7143702e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_72a36_row0_col0, #T_72a36_row0_col2 {\n",
       "  background-color: lightsalmon;\n",
       "}\n",
       "#T_72a36_row0_col1, #T_72a36_row1_col1, #T_72a36_row2_col1 {\n",
       "  background-color: palegreen;\n",
       "  background-color: lightsalmon;\n",
       "}\n",
       "#T_72a36_row2_col0, #T_72a36_row2_col2 {\n",
       "  background-color: palegreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_72a36_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >method</th>\n",
       "      <th class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th class=\"col_heading level0 col2\" >f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_72a36_level0_row0\" class=\"row_heading level0 row0\" >tfidf_full</th>\n",
       "      <td id=\"T_72a36_row0_col0\" class=\"data row0 col0\" >0.188</td>\n",
       "      <td id=\"T_72a36_row0_col1\" class=\"data row0 col1\" >0.327</td>\n",
       "      <td id=\"T_72a36_row0_col2\" class=\"data row0 col2\" >0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72a36_level0_row1\" class=\"row_heading level0 row1\" >tfidf_pos</th>\n",
       "      <td id=\"T_72a36_row1_col0\" class=\"data row1 col0\" >0.237</td>\n",
       "      <td id=\"T_72a36_row1_col1\" class=\"data row1 col1\" >0.327</td>\n",
       "      <td id=\"T_72a36_row1_col2\" class=\"data row1 col2\" >0.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72a36_level0_row2\" class=\"row_heading level0 row2\" >tfidf_anim</th>\n",
       "      <td id=\"T_72a36_row2_col0\" class=\"data row2 col0\" >0.240</td>\n",
       "      <td id=\"T_72a36_row2_col1\" class=\"data row2 col1\" >0.327</td>\n",
       "      <td id=\"T_72a36_row2_col2\" class=\"data row2 col2\" >0.270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x206206a9370>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = scores_df[6:9]\n",
    "tfidf_df.style.highlight_max(\n",
    "    color='palegreen', axis=0).highlight_min(\n",
    "    color='lightsalmon', axis=0).format('{:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2960d133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a2e03_row0_col0, #T_a2e03_row0_col2 {\n",
       "  background-color: lightsalmon;\n",
       "}\n",
       "#T_a2e03_row0_col1, #T_a2e03_row1_col1, #T_a2e03_row2_col1 {\n",
       "  background-color: palegreen;\n",
       "  background-color: lightsalmon;\n",
       "}\n",
       "#T_a2e03_row2_col0, #T_a2e03_row2_col2 {\n",
       "  background-color: palegreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a2e03_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >method</th>\n",
       "      <th class=\"col_heading level0 col0\" >precision</th>\n",
       "      <th class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th class=\"col_heading level0 col2\" >f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a2e03_level0_row0\" class=\"row_heading level0 row0\" >yake_full</th>\n",
       "      <td id=\"T_a2e03_row0_col0\" class=\"data row0 col0\" >0.065</td>\n",
       "      <td id=\"T_a2e03_row0_col1\" class=\"data row0 col1\" >0.148</td>\n",
       "      <td id=\"T_a2e03_row0_col2\" class=\"data row0 col2\" >0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2e03_level0_row1\" class=\"row_heading level0 row1\" >yake_pos</th>\n",
       "      <td id=\"T_a2e03_row1_col0\" class=\"data row1 col0\" >0.108</td>\n",
       "      <td id=\"T_a2e03_row1_col1\" class=\"data row1 col1\" >0.148</td>\n",
       "      <td id=\"T_a2e03_row1_col2\" class=\"data row1 col2\" >0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2e03_level0_row2\" class=\"row_heading level0 row2\" >yake_anim</th>\n",
       "      <td id=\"T_a2e03_row2_col0\" class=\"data row2 col0\" >0.114</td>\n",
       "      <td id=\"T_a2e03_row2_col1\" class=\"data row2 col1\" >0.148</td>\n",
       "      <td id=\"T_a2e03_row2_col2\" class=\"data row2 col2\" >0.126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2062069d5e0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yake_df = scores_df[9:12]\n",
    "yake_df.style.highlight_max(\n",
    "    color='palegreen', axis=0).highlight_min(\n",
    "    color='lightsalmon', axis=0).format('{:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b3ff5",
   "metadata": {},
   "source": [
    "Очевидно, что в 3 случаях из 4 использование шаблонов дает бОльшие значения precision и f1, чем не-использование, причем более \"продвинутые\" шаблоны дают бОльший прирост качества (хоть и незначительно). Recall практически не меняется (лишь незначительно у RAKE).\n",
    "\n",
    "\n",
    "#### Пункт 6. Описание ошибок и способы улучшения (1 балл)\n",
    "*Описать ошибки автоматического выделения ключевых слов (что выделяется лишнее, что не выделяется); предложить свои методы решения этих проблем.*\n",
    "\n",
    "##### Ошибки\n",
    "У всех методов, особенно у RAKE, много ложноположительных (предсказанных тегов, которых нет в эталоне). Это связано в т.ч. с количеством выдаваемых ключевых слов (у RAKE и YAKE оно получилось в среднем самое большое, см. пункт 2 улучшений). У TF-IDF precision ожидаемо выше, потому что был задан жесткий порог по числу ключевых слов (можно было бы задать его как долю от слов текста и посмотреть, что получится, но, скорее всего, это не улучшило бы результаты, потому что число слов в эталоне практически не зависит от длины текста; я попробовала это сделать для TextRank в пунтке 2 улучшений, результат ожидаемый).\n",
    "\n",
    "Полнота лучше всех у TF-IDF, т.е. в выделенные им ключевые слова и конструкции попало (относительно) много из того, что должно было попасть. Это несомненный плюс данного алгоритма, потому что у него размер выдачи был жестко ограничен, но это не помешало ему включить в нее достаточно много нужных слов. Из минусов можно отметить тот факт, что TF-IDF выделяет много повторов (*боровский, боровский птицефабрика, полигон боровский птицефабрика*), и на это никак нельзя повлиять (в отличие от, например, YAKE, где есть специальный отвечающий за это параметр.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99438c6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9:80: E501 line too long (87 > 79 characters)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст №1\n",
      "Эталон: брянский область, выходной, выходной день, коронавирус, курский область, локдаун, нерабочий день, новгородский область, регион, смоленский область, челябинский область\n",
      "RAKE: ввести, внести, неделя, нерабочий день, новгородский область, продление, регион, регион нерабочий день, ряд российский регион, сохранение заработный плата, удалённый формат взаимодействие, указ\n",
      "TextRank: власть, день, заработный, ноябрь, область, продлиться, регион, формат\n",
      "TF-IDF: день, нерабочий, нерабочий день, ноябрь, область, продлить, регион, режим, режим нерабочий день\n",
      "YAKE: власть, высокий учебный заведение, выходной, жвачкина, мера, ноябрь, режим повышенный готовность, решение, ряд, указ, учиться\n",
      "\n",
      "Текст №2\n",
      "Эталон: ан-12, гродно, иркутск, крушение, крушение самолёт, пивовариха, самолёт, тасс, экипаж\n",
      "RAKE: дождь, первый, приземлиться, смочь, ссылка\n",
      "TextRank: белорусский, который, помешать, самолёт, сообщать, член\n",
      "TF-IDF: белорусский, самолёт, село пивовариха, сообщать, член, член экипаж, экипаж\n",
      "YAKE: войти, иркутск, крушение, минтранс, ноябрь, самолёт, снег, создаваться, тело\n",
      "\n",
      "Текст №3\n",
      "Эталон: asl airlines belgium, boeing-747, аварийный посадка, новосибирск, самолёт\n",
      "RAKE: бельгия, инцидент, лететь, новосибирский аэропорт толмачево, ссылка\n",
      "TextRank: airlines, аэропорт, посадка, сообщать\n",
      "TF-IDF: аэропорт, двигатель, посадка, причина экстренный посадка, экстренный посадка\n",
      "YAKE: asl, asl airlines belgium, аэропорт толмачево, бельгия, инцидент, лететь, новосибирский, самолёт, судный\n",
      "\n",
      "Текст №4\n",
      "Эталон: газ, газпром, германия, европа, кублик, россия, северный поток-2, украина, экономика\n",
      "RAKE: газ, дно балтийский море, западный европа, использовать, настроение, незаинтересованность россия, нуль, прокачка российский газ, прошлый суббота, россия, украина\n",
      "TextRank: балтийский, газ, газа, газопровод, газпром, европа, журналист, концерн, кублик, поток, спрос, экономика\n",
      "TF-IDF: газ, газопровод, газпром, германия, европа, журналист, концерн, кублик, потоке, северный, северный потоке, спрос, экономика\n",
      "YAKE: газ, дно, кублик, новый, прим ред, спрос, страница аналитический выкладка, считать, украина\n",
      "\n",
      "Текст №5\n",
      "Эталон: александр зверев, андрей рублёв, григор димитров, душан лайович, карен хачан, париж, теннис, теннисный турнир, турнир\n",
      "RAKE: карен хачан, матч, париж теннисный турнир, призовой фонд\n",
      "TextRank: завершить, карен, круг, лайович, сет, теннисист\n",
      "TF-IDF: григор, григор димитров, димитров, завершить, карен, карен хачан, круг, париж, сет, теннисист, турнир, хачан, час\n",
      "YAKE: выйти, играть, минута, париж теннисный турнир, рублёв, сет, смочь, фонд, час\n",
      "\n",
      "Текст №6\n",
      "Эталон: андрей малахов, концлагерь, новость, приёмный семья, программа, прямой эфир, россия 1, семья, телеведущий\n",
      "RAKE: бабушка, больший прекрасный семья, воспитание, воспроизвести, вырастить, деньга, добавить, должный, дочь, думать, женщина, жизнь, забота, забрать, концлагерь, младенчество сестрёнка, момент, огромный, отработать, приёмный семья, пройти, рассказать, решить, родный, семья, сестра, смочь, страдать, судьба, узнать, чувствовать, чужой, являться\n",
      "TextRank: брат, вырасти, гость, день, канал россия, мочь, наш, программа, родитель, телеведущий арча, тест, эксперт\n",
      "TF-IDF: алевтина, арча, вырасти, женщина, приёмный, программа, родитель, родный, светлана, семья, сестра, телеведущий, эксперт\n",
      "YAKE: smotrim, арча, биологический, выпуск, женщина, любовь, родный, свой, семья, сосуд, тест, узнать, эфир канал\n",
      "\n",
      "Текст №7\n",
      "Эталон: боровский птицефабрика, владимир чеймет, заразить, птицефабрика, птичий грипп, россельхознадзор, тюмень, утилизация\n",
      "RAKE: время, вспышка грипп, итог предприятие, октябрь, площадь, полигон, полигон боровский птицефабрика, представить, сообщение\n",
      "TextRank: \n",
      "TF-IDF: биоматериал, боровский, боровский птицефабрика, гореть, грипп, жечь, кура, полигон, полигон боровский птицефабрика, продукция, птица, птицефабрика\n",
      "YAKE: telegram-канал опративный штаб, владимир чеймет, вспышка, гектар, гореть, запах, кура, миллион яйцо, очаг, полигон боровский птицефабрика, продукция, расчёт, специфический запах горение, тонна\n",
      "\n",
      "Текст №8\n",
      "Эталон: арест, блогер, крест, норд-ост, петербург, сизый, суд, терроризм, юрий хованский\n",
      "RAKE: вера, вина, внести, время прямой эфир, глумиться, дело, квартира, который, кровообращение, месяц, мюзикл норд-ост, оправдание терроризм из-, песня, петербург, проблема, пропаганда, пушкинский улица, сизый из-, соцсеть повод, спеть, человечество, экстремист\n",
      "TextRank: блогер, год, дальнейший, норд, песня, подрывать, прямой, список, стать, хованский\n",
      "TF-IDF: блогер, блогер юрий, год, оправдание, оправдание терроризм, песня, петербург, сизый, терроризм, хованский, юрий, юрий хованский\n",
      "YAKE: дело, заявить, июнь, куйбышевский районный суд, мюзикл норд-ост, орган, песня, повод, прямой эфир, публичный оправдание, суд, теракт, улица, юрий\n",
      "\n",
      "Текст №9\n",
      "Эталон: covid-19, qr-код, гтрк смоленск, локдаун, нерабочий день, пцр-тест, регион, смоленский область\n",
      "RAKE: ввести, действовать, документ, нерабочий день, новгородский область, предыдущий редакция указ, регион, сертификат\n",
      "TextRank: день, документ, мера, очередь, смоленск, смоленский область\n",
      "TF-IDF: документ, ноябрь, область, посетитель, смоленский, смоленский область, указ\n",
      "YAKE: ввести, глава, гтрк, губернатор, медотвод, ноябрь, режим, указ, челябинский\n",
      "\n",
      "Текст №10\n",
      "Эталон: qr-код, алексей дюмин, гтрк тула, дмитрий марков, коронавирус, нерабочий день, ограничение, регион, тула, тульский область\n",
      "RAKE: вход, входить, житель, наш регион, область, предприятие, пресс-служба региональный правительство, регион, ссылка, учреждение\n",
      "TextRank: группа, гтрк, здравоохранение, место, ограничение, оперштаб, распространение\n",
      "TF-IDF: qr, глава регион, день, заявить, код, нерабочий, нерабочий день, область, продлевать, регион, тульский, тульский область\n",
      "YAKE: qr-код, алексей дюмин, врач, главный, гтрк тула, губернатор, область, регион, слово глава, снижение\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# простите за длинный принт, корпус большой :(\n",
    "for i in range(10):\n",
    "    gold = ', '.join(sorted(gold_tags[i]))\n",
    "    rake = ', '.join(sorted(rake_with_animacy[i]))\n",
    "    textrank = ', '.join(sorted(textrank_with_animacy[i]))\n",
    "    tfidf = ', '.join(sorted(tfidf_with_animacy[i]))\n",
    "    yake = ', '.join(sorted(yake_with_animacy[i]))\n",
    "    print(\n",
    "        'Текст №{}\\nЭталон: {}\\nRAKE: {}\\nTextRank: {}\\nTF-IDF: {}\\nYAKE: {}\\n'.format(\n",
    "            i+1, gold, rake, textrank, tfidf, yake))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de282e",
   "metadata": {},
   "source": [
    "Видно, что среди автоматически выделенных ключевых слов, особенно в выдаче TextRank и YAKE, многовато глаголов (в эталоне они тоже встречались, раз появился такой шаблон, но намного реже: человеку более свойственно выделять в качестве ключевых именные группы). Возможное решение в пункте 3 улучшений.\n",
    "\n",
    "\n",
    "##### Улучшения\n",
    "1. Первое улучшение пришло мне в голову еще при выполнении 4 пункта, и я его уже реализовала: это использование дополнительной морфосинтаксической информации в шаблонах. В моем случае это только одушевленность, потому что остальная информация теряется при лемматизации (или вообще не имеет смысла, как род для существительных). На собранных данных получилось, что более подробный шаблон сработал лучше (хотя отличия минимальные).\n",
    "\n",
    "\n",
    "2. Хочется как-то фильтровать ключевые слова, выдаваемые RAKE, потому что он почти всегда выдает больше, чем есть в эталоне, причем довольно значительно -- в 3-4 раза (на моем корпусе из 40 текстов обратная ситуация встретилась только трижды). То же самое для TextRank: доля выделяемых ключевых слов одинаковая для всего корпуса, а длина текстов в корпусе варьируется; при этом в эталоне число ключевых слов от 3 до 13, но чаще всего в диапазоне 6-9. **Апдейт**: я попробовала выставить для RAKE порог по частотности как долю от самого большого скора, получилось даже хуже, чем было))) Мне все еще хочется как-то фильтровать результаты, но я не очень представляю, как. **Апдейт 2**: для TextRank уменьшение ratio с дефолтного 0.2 до 0.15/0.1 дает прирост precision, но ухудшение recall (логично, меньше выдача --> меньше ложноположительных, но и меньше шанс, что в выдачу попадет все нужное). Я остановилась на ratio=0.15 как среднем варианте. См. картинку. ![Качество работы TextRank при ratio = 0.2, 0.15, 0.1](textrank.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8542c61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.042, 0.057, 0.045]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# фильтрация выдачи RAKE по скору\n",
    "\n",
    "rake_test = []\n",
    "for art in rake_nonzero:\n",
    "    new = []\n",
    "    top_score = art[0][1]\n",
    "    for kw in art:\n",
    "        # пробовала долю от 0.05 до 0.3, чем меньше, тем лучше\n",
    "        # т.е. лучше не фильтровать\n",
    "        if kw[1] >= top_score * 0.2:\n",
    "            new.append(kw[0])\n",
    "    rake_test.append(new)\n",
    "\n",
    "# для предсказаний без шаблонов\n",
    "evaluate_all(gold_tags, rake_test)  # было 0.063, 0.151, 0.083"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf4c361",
   "metadata": {},
   "source": [
    "3. Можно попробовать учитывать не все шаблоны, а только самые частотные, но тогда нужно применять шаблоны и к самому эталону, иначе мы заведомо оставляем в эталоне что-то, что никак не может попасть в отфильтрованные предсказания (эта мысль была в беседе курса, я ее туда и писала))). Отчасти в этом есть смысл, потому что эталон не идеален (может быть, я один раз включила какую-то редкую конструкцию, а потом вытащила из предсказаний все n-граммы по этому шаблону, и получилось много лишнего).\n",
    "\n",
    "\n",
    "4. Шаблоны далеки от идеала как минимум потому, что не идеальна разметка пайморфи. Например, некоторые слова он помечает как UNKN (не распознано), и непонятно, как относиться к этому тегу. В этой домашке принято волевое решение не считать UNKN за шаблон, что может быть не очень правильно, потому что в эталоне слова с таким тегом остаются, а в отфильтрованные предсказания попасть не могут, -- ровно та проблема, которая описана в абзаце выше. Все остальные варианты (NUMB и LATN) я учла, но на новых данных может вылезти еще что-то, что не попадает в поле POS и не будет учтено в шаблонах. Здесь возможное улучшение -- использовать другой парсе (об этом также в пункте 8).\n",
    "\n",
    "\n",
    "5. При автоматическом выделении ключевых слов можно использовать дополнительную информацию, например, считать более важными те слова, которые встретились и в самом тексте, и в заголовке новости. Похожий подход можно использовать и при оценке результатов, сильнее штрафуя за не-выявление наиболее важных ключевых слов (более частотных / встретившихся в заголовке и т.д.)\n",
    "\n",
    "\n",
    "6. Для TF-IDF хорошо бы использовать корпус побольше, иначе теряется смысл метода (но все-таки 40 текстов лучше, чем 4-5).\n",
    "\n",
    "\n",
    "7. Выбранные метрики не очень подходят для оценки качества уже потому, что практически всегда имеет место несовпадение числа ключевых слов в эталоне и в выдаче разных алгоритмов, плюс опять-таки нужно учитывать важность тех или иных ключевых слов, а в нашем случае это невозможно уже потому, что эталон такой информации не содержит. В реальной задаче имело бы смысл использовать метрики, разработанные специально для выявления и ранжирования ключевых слов (Mean Reciprocal Rank, Mean Average Precision и т.д.)\n",
    "\n",
    "\n",
    "8. Кое-где появились ошибки лемматизации, из-за которых выявились лишние ключевые слова (\"газ\" и \"газа\" в тексте №4) или выявилась другая форма ключевого слова (что, естественно, отразилось на метриках). Можно попробовать какой-то другой парсер (я хотела взять майстем, но библиотека на винде работает медленно, а с консольным мне было очень лень возиться).\n",
    "\n",
    "\n",
    "9. И мое любимое -- доработать эталон :) Даже при всех произведенных ухищрениях в нем очень силен человеческий фактор. Если бы мы хотели использовать этот шаблон для какой-то реальной задачи, потребовалась бы независимая разметка ключевых слов несколькими экспертами с последующим формированием эталона на основе каким-то объективных критериев (например, сколько раз то или иное слово/конструкция встретилось в разметке разных людей)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
