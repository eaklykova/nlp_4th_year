{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f2eddc",
   "metadata": {},
   "source": [
    "# Д/З 2: Извлечение коллокаций + NER\n",
    "### Выполнила Елизавета Клыкова, БКЛ181\n",
    "### Пункт 0: получение и очистка датасета\n",
    "*Выберите корпус отзывов на товары одной из категорий Amazon: http://jmcauley.ucsd.edu/data/amazon/.*\n",
    "\n",
    "Я остановилась на датасете [5-core Kindle Store](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Kindle_Store_5.json.gz) -- архив с ним весит 259 Мб, поэтому на гитхаб не выкладываю. Перед запуском программы его нужно распаковать.\n",
    "\n",
    "Заранее извиняюсь за некоторую костыльность кода, заключающуюся в бесконечном создании / открывании файлов, но на обработку всего каждый раз мне не хватало ни оперативной памяти, ни терпения :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9ae468",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecdf152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "import html\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from heapq import nlargest\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from summa import keywords\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1116bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 117\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced5c47",
   "metadata": {},
   "source": [
    "(можно не запускать, все сохранено в файл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b0083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# не забыть распаковать архив\n",
    "with open('Kindle_Store_5.json', encoding='utf-8') as f:\n",
    "    rev_lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e04ca1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15615303466a4420bdf5936e0f060e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/982619 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews = [json.loads(rev) for rev in tqdm(rev_lines)]\n",
    "item_ids = set([rev['asin'] for rev in reviews])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b121355",
   "metadata": {},
   "source": [
    "Теперь возьмем [метаданные](http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles2/meta_Kindle_Store.json.gz) (архив весит 96 Мб)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fba325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# не забыть распаковать архив\n",
    "with open('meta_Kindle_Store.json', encoding='utf-8') as f:\n",
    "    meta_lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "290a5aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84dcd73e90234828bb257b699dfb539c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/491670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta = []\n",
    "for line in tqdm(meta_lines):\n",
    "    item_meta = json.loads(line)\n",
    "    # сразу берем только нужные метаданные\n",
    "    if item_meta['asin'] in item_ids:\n",
    "        meta.append(item_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa31c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_ids = set([product['asin'] for product in meta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7f52d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b4f471a4114c8db6810bceefba5755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31889 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta_dict = {item['asin']: item for item in tqdm(meta)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cc66df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc446b55ebb477f95b389a21c64bddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/982619 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# так и не смогла побороть df.merge(), так что будет костыль\n",
    "reviews_with_meta = []\n",
    "\n",
    "for review in tqdm(reviews):\n",
    "    prod_id = review['asin']\n",
    "    if prod_id in meta_ids:\n",
    "        meta_info = meta_dict[prod_id]\n",
    "        review_info = {'asin': prod_id,\n",
    "                       'reviewerID': review['reviewerID'],\n",
    "                       'overall': review['overall'],\n",
    "                       'summary': review['summary'],\n",
    "                       'reviewText': review['reviewText'],\n",
    "                       'title': meta_info['title'],\n",
    "                       'brand': meta_info['brand'],\n",
    "                       'main_cat': meta_info['main_cat'],\n",
    "                       'category': meta_info['category'],\n",
    "                       'description': meta_info['description'],\n",
    "                       'feature': meta_info['feature']}\n",
    "        reviews_with_meta.append(review_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f348aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485925"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_df = pd.DataFrame(reviews_with_meta)\n",
    "rev_df.astype(str).drop_duplicates(inplace=True)\n",
    "rev_df.reset_index(drop=True, inplace=True)\n",
    "len(rev_df)  # 485925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f09653fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485134"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([t for t in rev_df['title'].tolist() if t])  # 485134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a40c2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([t for t in rev_df['description'].tolist() if t])  # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39db58d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([t for t in rev_df['feature'].tolist() if t])  # 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f6182",
   "metadata": {},
   "source": [
    "Название товара почти у всех отзывов на месте, а вот колонки description и feature оказались пустыми, избавимся от них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "684f6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_df.drop(columns=['description', 'feature'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72064c7",
   "metadata": {},
   "source": [
    "Немного почистим метаданные (приведем в более читаемый формат)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14cdffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(some_string):\n",
    "    no_html = html.unescape(some_string)\n",
    "    no_tags = re.sub('<.*?>', '', no_html)\n",
    "    no_abrs = no_tags.replace(' w/', ' with ').replace('(w/', '(with ')\n",
    "    return no_abrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c3f4317",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_df['title'] = rev_df['title'].apply(lambda x: clean_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9df40225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column(df, some_column):\n",
    "    values = [[clean_string(value) for value in row]\n",
    "              for row in df[some_column].tolist()]\n",
    "    df[some_column] = [[v for v in row if v] for row in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10ad9de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_column(rev_df, 'category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663403d2",
   "metadata": {},
   "source": [
    "Также удалим строки, в которых нет текста отзыва, названия товара или категорий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95c770f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_df.replace('', np.nan, inplace=True)\n",
    "rev_df['category'] = rev_df['category'].apply(\n",
    "    lambda x: np.nan if len(x) == 0 else x)\n",
    "rev_df.dropna(subset=['reviewText', 'title', 'category'], inplace=True)\n",
    "len(rev_df)  # 485125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cb51558",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_df.to_csv('kindle_reviews.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff47ac4",
   "metadata": {},
   "source": [
    "Поскольку файлы очень тяжелые, а у меня маниакальная любовь перезапускать тетрадки, сохраним полученный датафрейм в файл, чтобы можно было считывать оттуда и не повторять препроцессинг каждый раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c957d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_df = pd.read_csv('kindle_reviews.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fec8d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_list(df, column):\n",
    "    str_reprs = df[column].tolist()\n",
    "    df[column] = [ast.literal_eval(s) for s in str_reprs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02cb4580",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_list(rev_df, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efc633ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0012W11D0</td>\n",
       "      <td>AL6WDE46RJ9I3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HOT TICKET by K. A. Mitchell</td>\n",
       "      <td>I loved the wonderfulDiving in Deepby K. A. Mi...</td>\n",
       "      <td>Hot Ticket (Serving Love) - Kindle edition</td>\n",
       "      <td>Visit Amazon's K.A. Mitchell Page</td>\n",
       "      <td>Buy a Kindle</td>\n",
       "      <td>[Kindle Store, Kindle eBooks, Literature &amp; Fic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0012W11D0</td>\n",
       "      <td>A14R9XMZVJ6INB</td>\n",
       "      <td>3.0</td>\n",
       "      <td>hot while you are reading it,  easily forgotte...</td>\n",
       "      <td>Light, short novella, nothing too deep - Cade ...</td>\n",
       "      <td>Hot Ticket (Serving Love) - Kindle edition</td>\n",
       "      <td>Visit Amazon's K.A. Mitchell Page</td>\n",
       "      <td>Buy a Kindle</td>\n",
       "      <td>[Kindle Store, Kindle eBooks, Literature &amp; Fic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0012W11D0</td>\n",
       "      <td>A1ZVW3VWAASU2Z</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Just OK</td>\n",
       "      <td>Have to admit I expected more even though it i...</td>\n",
       "      <td>Hot Ticket (Serving Love) - Kindle edition</td>\n",
       "      <td>Visit Amazon's K.A. Mitchell Page</td>\n",
       "      <td>Buy a Kindle</td>\n",
       "      <td>[Kindle Store, Kindle eBooks, Literature &amp; Fic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0012W11D0</td>\n",
       "      <td>A1XFKGZYK3N43L</td>\n",
       "      <td>5.0</td>\n",
       "      <td>When two world collides</td>\n",
       "      <td>This is the best to describe this book due to ...</td>\n",
       "      <td>Hot Ticket (Serving Love) - Kindle edition</td>\n",
       "      <td>Visit Amazon's K.A. Mitchell Page</td>\n",
       "      <td>Buy a Kindle</td>\n",
       "      <td>[Kindle Store, Kindle eBooks, Literature &amp; Fic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0012W11D0</td>\n",
       "      <td>A13QTZ8CIMHHG4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Irresistable Read</td>\n",
       "      <td>Who knew community service could be so...sexy?...</td>\n",
       "      <td>Hot Ticket (Serving Love) - Kindle edition</td>\n",
       "      <td>Visit Amazon's K.A. Mitchell Page</td>\n",
       "      <td>Buy a Kindle</td>\n",
       "      <td>[Kindle Store, Kindle eBooks, Literature &amp; Fic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin      reviewerID  overall  \\\n",
       "0  B0012W11D0   AL6WDE46RJ9I3      4.0   \n",
       "1  B0012W11D0  A14R9XMZVJ6INB      3.0   \n",
       "2  B0012W11D0  A1ZVW3VWAASU2Z      3.0   \n",
       "3  B0012W11D0  A1XFKGZYK3N43L      5.0   \n",
       "4  B0012W11D0  A13QTZ8CIMHHG4      5.0   \n",
       "\n",
       "                                             summary  \\\n",
       "0                       HOT TICKET by K. A. Mitchell   \n",
       "1  hot while you are reading it,  easily forgotte...   \n",
       "2                                            Just OK   \n",
       "3                            When two world collides   \n",
       "4                                  Irresistable Read   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  I loved the wonderfulDiving in Deepby K. A. Mi...   \n",
       "1  Light, short novella, nothing too deep - Cade ...   \n",
       "2  Have to admit I expected more even though it i...   \n",
       "3  This is the best to describe this book due to ...   \n",
       "4  Who knew community service could be so...sexy?...   \n",
       "\n",
       "                                        title  \\\n",
       "0  Hot Ticket (Serving Love) - Kindle edition   \n",
       "1  Hot Ticket (Serving Love) - Kindle edition   \n",
       "2  Hot Ticket (Serving Love) - Kindle edition   \n",
       "3  Hot Ticket (Serving Love) - Kindle edition   \n",
       "4  Hot Ticket (Serving Love) - Kindle edition   \n",
       "\n",
       "                               brand      main_cat  \\\n",
       "0  Visit Amazon's K.A. Mitchell Page  Buy a Kindle   \n",
       "1  Visit Amazon's K.A. Mitchell Page  Buy a Kindle   \n",
       "2  Visit Amazon's K.A. Mitchell Page  Buy a Kindle   \n",
       "3  Visit Amazon's K.A. Mitchell Page  Buy a Kindle   \n",
       "4  Visit Amazon's K.A. Mitchell Page  Buy a Kindle   \n",
       "\n",
       "                                            category  \n",
       "0  [Kindle Store, Kindle eBooks, Literature & Fic...  \n",
       "1  [Kindle Store, Kindle eBooks, Literature & Fic...  \n",
       "2  [Kindle Store, Kindle eBooks, Literature & Fic...  \n",
       "3  [Kindle Store, Kindle eBooks, Literature & Fic...  \n",
       "4  [Kindle Store, Kindle eBooks, Literature & Fic...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b0509b",
   "metadata": {},
   "source": [
    "### Пункт 1: способы выделения названий (3 балла)\n",
    "*Предложите 3 способа найти упоминания товаров в отзывах. Например, использовать bootstrapping: составить шаблоны вида \"холодильник XXX\", найти все соответствующие n-граммы и выделить из них называние товара. Могут помочь заголовки и дополнительные данные с Amazon. Какие данные необходимы для каждого из способов? Какие есть достоинства/недостатки?*\n",
    "\n",
    "1. Использовать существительные / именные группы / именованные сущности из метаданных.\n",
    "    * Суть: взять названия и описания товаров, извлечь названия и искать в отзывах\n",
    "    * Данные: метаданные о товарах\n",
    "    * Достоинства: дешево и сердито\n",
    "    * Недостатки: очень грязный способ: при автоматическом выделении попадает много лишнего, трудно отсеять существительные / именные группы / сущности, которые называют именно сам товар; не факт, что в отзыве обязательно встретятся слова из названия/описания; если брать существительные, то длина названия ограничена одним словом\n",
    "    * Возможное улучшение: добавить ручной отбор слов, которые попадают в потенциальные названия; взять названия (и м.б. описания) товаров, проанализировать, посмотреть на частотные существительные, составить список наименований\n",
    "2. Использовать морфосинтаксические шаблоны (как в д/з 1).\n",
    "    * Суть: взять названия, выделенные способом 1 (с улучшением), и составить шаблоны с ними\n",
    "    * Данные: метаданные о товаров + собственная фантазия\n",
    "    * Достоинства: длина наименования ограничена не одним словом, а тем количеством, которое допускают шаблоны\n",
    "    * Недостатки: много мусора (в д/з 1 под шаблоны подходило много того, что не должно было бы); при написании правил невозможно учесть все реальные случаи\n",
    "3. Использовать ключевые слова.\n",
    "    * Суть: выделять ключевые слова из отзывов и искать пересечения с терминами, полученными из названий / описаний\n",
    "    * Данные: метаданные о товарах\n",
    "    * Достоинства: вычислительно проще, чем следующие два способа; в идеале алгоритмы будут находить слова, которые действительно важны для отзыва (в противовес обычному выделению существительных, которое даст кучу мусора)\n",
    "    * Недостатки: очень строгий способ отбора слов (если берем пересечение, слов может вообще не остаться); алгоритмы выделения ключевых слов не идеальны\n",
    "4. Использовать синонимы/гиперонимы/гипонимы.\n",
    "    * Суть: расширить список слов из названия и описания товаров синонимичными словами и более общими названиями классов\n",
    "    * Данные: метаданные о товарах + источники синонимов/гиперонимов/гипонимов (например, WordNet)\n",
    "    * Достоинства: поможет избежать проблемы отсутствия слов из названия/описания в отзыве\n",
    "    * Недостатки: потенциальное (еще большее) загрязнение данных -- попадание в них слов, которые не могут относиться к товару (т.к. в WordNet может быть огромное количество слов, если брать и синонимы, и гиперонимы, и гипонимы); невозможность искать синонимы для конструкций (только для отдельных слов)\n",
    "5. Использовать векторные модели.\n",
    "    * Суть: для выделенных в первом способе слов (из названия и описания) искать похожие слова внутри отзывов\n",
    "    * Данные: метаданные + векторная модель\n",
    "    * Достоинства: возможность бороться с отсутствием слов из названия/описания в отзыве + отсутствие мусора в данных (т.к. берем сразу только то, что гарантированно есть в отзывах)\n",
    "    * Недостатки: непонятно, как определять \"похожесть\" слов. Просто самые похожие? Но это может быть что угодно, мало ли мусора в отзывах. Выбирать порог близости? Это не самая тривиальная задача и, пожалуй, больше в рамках информационного поиска. Наконец, как и в способе 3, нельзя посчитать близость, если в названии не 1 одно слово. (+ маленький размер корпуса, но можно просто взять датасет побольше)\n",
    "6. Использовать готовые инструменты для извлечения именованных сущностей.\n",
    "    * Суть: искать в отзывах именованные сущности и сопоставлять их с тем, что мы находим в названиях товаров (возможно, с помощью тех же инструментов\n",
    "    * Данные: названия товаров\n",
    "    * Достоинства: почти ничего не надо делать, все уже написано за нас\n",
    "    * Недостатки: пожалуй, самый грязный способ, особенно на наших данных. Во-первых, в заголовках почти все слова с большой буквы, поэтому тот же spacy считает их все за имена собственные. Во-вторых, в отзывах никто обычно не пишет полное название, и даже не обязательно указывают бренд. Условно, если мы пишем отзыв на телефон Honor 10 xxx-xxx (код модели), мы напишем просто \"телефон\" или в крайнем случае \"гаджет\".\n",
    "\n",
    "### Пункт 2: реализация одного из способов (2 балла)\n",
    "*Реализуйте один из предложенных вами способов.*\n",
    "\n",
    "Изначально я планировала реализовать способ с векторными моделями, но в процессе поняла, что комбинировать интереснее.\n",
    "\n",
    "Первый шаг -- выделить из метаданных существительные, обозначающие товары. Попробуем начать с категорий: это закрытый класс, поэтому он чище, чем названия, в которые пытаются запихать всю возможную информацию (в т.ч. с сокращениями, что затрудняет частеречную разметку).\n",
    "#### Категории + названия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "344e5f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = rev_df['category'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ec4efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cats = []\n",
    "for item in categories:\n",
    "    all_cats.extend(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da33fdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Kindle Store', 485125),\n",
       " ('Kindle eBooks', 484161),\n",
       " ('Literature & Fiction', 222413),\n",
       " ('Romance', 93377),\n",
       " ('Science Fiction & Fantasy', 32885),\n",
       " (\"Children's eBooks\", 19671),\n",
       " ('Mystery, Thriller & Suspense', 19658),\n",
       " ('Religion & Spirituality', 17876),\n",
       " ('Health, Fitness & Dieting', 16579),\n",
       " ('Teen & Young Adult', 15407),\n",
       " ('Cookbooks, Food & Wine', 10021),\n",
       " ('Business & Money', 9903),\n",
       " ('Crafts, Hobbies & Home', 3266),\n",
       " ('Biographies & Memoirs', 2737),\n",
       " ('Humor & Entertainment', 2622),\n",
       " ('Self-Help', 2167),\n",
       " ('History', 2067),\n",
       " ('Parenting & Relationships', 2033),\n",
       " ('Reference', 1675),\n",
       " ('Education & Teaching', 1571)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_counter = Counter(all_cats)\n",
    "print(len(cat_counter))\n",
    "cat_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0126781a",
   "metadata": {},
   "source": [
    "Кажется, нам повезло найти хороший однородный датасет (на самом деле никакого везения, я сменила четыре штуки...). Для дальнейшего анализа возьмем все, что в категории \"Kindle eBooks.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "badf04be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484161"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = rev_df[pd.DataFrame(\n",
    "    rev_df['category'].tolist()).isin(['Kindle eBooks']).any(1).values]\n",
    "len(sub_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83fa0a",
   "metadata": {},
   "source": [
    "Небольшая проблема: в категориях почти нет существительных, способных называть сам товар. Они описывают скорее жанр или тему. Из списка выше в качестве существительных мы скорее хотим видеть слова ebook и memoir, но не hobbies и relationships. Скорее всего, слова придется отбирать вручную. Но сначала разметим существительные с помощью spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3902a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# если не работает, переустановить через командную строку\n",
    "# минус два часа моей жизни\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9910a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78265952",
   "metadata": {},
   "source": [
    "Небольшая проблема -- spacy очень чувствителен к регистру и помечает все, что написано с большой буквы, как имя собственное. (NLTK, кстати, тоже этим страдает, я пробовала и его.) Придется привести все к нижнему регистру, что тоже не оптимально, потому что мы можем потерять какую-то важную информацию, но тут ничего не поделаешь: написание всего, кроме предлогов и союзов, с большой буквы, -- это специфика названий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8777ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_lower = [cat.lower() for cat in list(set(all_cats))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "835559c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc29f45bc6324928841e7d389a1fe268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tagged_cats = []\n",
    "\n",
    "for doc in tqdm(nlp.pipe(cats_lower, disable=['parser', 'ner']),\n",
    "                total=len(cats_lower)):\n",
    "    tagged_cats.append([(tok.text, tok.lemma_, tok.pos_) for tok in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46233f6",
   "metadata": {},
   "source": [
    "Будем брать леммы слов, потому что категория часто называется во множественном числе, а сам товар скорее будет в единственном."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b15cedde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_nouns = []\n",
    "for cat in tagged_cats:\n",
    "    for pair in cat:\n",
    "        if pair[-1] == 'NOUN' or pair[-1] == 'PROPN':\n",
    "            cat_nouns.append(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebf7fdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(cat_nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29bda2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kindle', 'page', 'minute', 'generation', 'science', 'paperwhite', 'fiction', 'hour', 'ebooks', 'art', 'entertainment', 'computer', 'technology', 'blog', 'romance', 'nonfiction', 'read', 'literature', 'health', 'fitness', 'dieting', 'law', 'biography', 'memoir', 'cookbooks', 'food', 'wine', 'touch', 'child', 'ebook', 'engineering', 'transportation', 'voyage', 'reference', 'mystery', 'thriller', 'suspense', 'business', 'money', 'dx', 'history', 'math', 'store', 'keyboard', 'teen', 'adult', 'politics', 'social', 'sport', 'outdoor', 'education', 'teaching', 'humor', 'comic_strip', 'manga', 'novel', 'parenting', 'relationship', 'religion', 'spirituality', 'travel', 'language', 'self', 'help', 'craft', 'hobby', 'home', 'photography', 'fantasy']\n"
     ]
    }
   ],
   "source": [
    "print([noun[0] for noun in Counter(cat_nouns).most_common()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55398ea4",
   "metadata": {},
   "source": [
    "Отсюда нам подходят слова ebooks, manga, novel, ebook, cookbooks, thriller, biography, memoir (и то некоторые -- с натяжкой). Посмотрим, что бывает в названиях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be169fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [t.lower() for t in set(rev_df['title'].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e07c0d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffaee57d982f4c69b228f4856ded0561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tagged_titles = []\n",
    "\n",
    "for doc in tqdm(nlp.pipe(titles, disable=['parser', 'ner']),\n",
    "                total=len(titles)):\n",
    "    tagged_titles.append([(tok.text, tok.lemma_, tok.pos_) for tok in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7054349",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_nouns = []\n",
    "for title in tagged_titles:\n",
    "    for pair in title:\n",
    "        if pair[-1] == 'NOUN' or pair[-1] == 'PROPN':\n",
    "            title_nouns.append(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64aa4291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13035"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(title_nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f5a6b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kindle', 23844),\n",
       " ('edition', 23755),\n",
       " ('book', 12237),\n",
       " ('ebook', 4404),\n",
       " ('series', 3809),\n",
       " ('romance', 1698),\n",
       " ('story', 1486),\n",
       " ('recipe', 1274),\n",
       " ('love', 1241),\n",
       " ('guide', 854),\n",
       " ('life', 757),\n",
       " ('mystery', 751),\n",
       " ('child', 701),\n",
       " ('kid', 668),\n",
       " ('weight', 634),\n",
       " ('diet', 590),\n",
       " ('novel', 542),\n",
       " ('christmas', 539),\n",
       " ('heart', 523),\n",
       " ('trilogy', 513)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(title_nouns).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9ffecb",
   "metadata": {},
   "source": [
    "Ого, получилось довольно осмысленно! Я предполагала, что существительные из названий окажутся бесполезными для нашей задачи, потому что в отзыве человек скорее напишет \"эта книга / серия / роман\", а не само название, но, очевидно, названия электронных книг на Амазоне не ограничиваются собственно заглавием и именем автора.\n",
    "\n",
    "Посмотрим на 50 самых частотных существительных и вручную выберем те из них, которые могут относиться к товару."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa909889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kindle', 'edition', 'book', 'ebook', 'series', 'romance', 'story', 'recipe', 'love', 'guide', 'life', 'mystery', 'child', 'kid', 'weight', 'diet', 'novel', 'christmas', 'heart', 'trilogy', 'part', 'loss', 'man', 'collection', 'day', 'novella', 'time', 'secret', 'billionaire', 'family', 'beginner', 'night', 'picture', 'tale', 'girl', 'animal', 'adventure', 'publishing', 'woman', 'world', 'bride', 'wolf', 'fire', 'volume', 'self', 'blood', 'home', 'fact', 'way', 'cookbook', 'health', '.', 'thriller', 'stress', 'set', 'age', 'food', 'oil', 'angel', 'dog', 'money', 'star', 'murder', 'dream', 'moon', 'baby', 'saga', 'step', 'boy', 'fun', 'order', 'friend', 'game', 'tip', 'chronicle', 'box', 'regency', 'club', 'alpha', 'desire', 'shadow', 'war', 'cure', 'menage', 'dragon', 'mail', 'body', 'cowboy', 'suspense', 'soul', 'king', 'cat', 'vampire', 'adult', 'chance', 'anxiety', 'lover', 'paleo', 'rock', 'power']\n"
     ]
    }
   ],
   "source": [
    "print([noun[0] for noun in Counter(title_nouns).most_common(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b75baea",
   "metadata": {},
   "source": [
    "Интересная тенденция: чем выше слово в списке, тем больше оно нам подходит; чем ниже, тем больше вероятность, что это часть темы или названия. Теперь выберем нужные нам слова, не забыв про те, которые мы выделили из категорий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "975c3fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_set = ['ebooks', 'manga', 'novel', 'ebook',\n",
    "            'thriller', 'biography', 'memoir'] + \\\n",
    "           ['edition', 'book', 'series', 'story',\n",
    "            'guide', 'novel', 'trilogy', 'collection',\n",
    "            'novella', 'tale', 'volume', 'cookbook', 'saga']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d519a",
   "metadata": {},
   "source": [
    "#### Отзывы\n",
    "Теперь посмотрим на то, что содержится в отзывах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1594f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = rev_df['reviewText'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822fd791",
   "metadata": {},
   "source": [
    "ЧАСТЬ С РАЗМЕТКОЙ -- НЕ ЗАПУСКАТЬ ИНАЧЕ СМЕРТЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fce569",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_nouns = []\n",
    "lem_texts = []\n",
    "\n",
    "for doc in tqdm(nlp.pipe(texts, disable=['parser', 'ner']),\n",
    "                total=len(texts)):\n",
    "    lem_text = []\n",
    "\n",
    "    for tok in doc:\n",
    "        lemma = tok.lemma_\n",
    "        pos = tok.pos_\n",
    "        if pos != 'PUNCT':\n",
    "            lem_text.append(lemma)\n",
    "        if pos == 'NOUN' or pos == 'PROPN':\n",
    "            text_nouns.append(lemma)\n",
    "\n",
    "    lem_texts.append(lem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36e219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tagged_texts.pickle', 'wb') as f:\n",
    "    pickle.dump((Counter(text_nouns).most_common(100),\n",
    "                 lem_texts), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adbdc00",
   "metadata": {},
   "source": [
    "ЗАПУСКАТЬ ОТСЮДА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a79ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tagged_texts.pickle', 'rb') as f:\n",
    "    noun_counter, lem_texts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34add1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'story', 'character', 'series', 'author', 'time', 'love', 'life', 'way', 'read', 'thing', 'one', 'romance', 'man', 'lot', 'friend', 'end', 'part', 'people', 'year', 'review', 'woman', 'relationship', 'reader', 'family', 'world', 'bit', 'page', 'novel', 'plot', 'sex', 'day', 'scene', 'heart', 'star', 'job', 'writing', 'girl', 'ending', 'action', 'child', 'work', 'line', 'guy', 'word', 'point', 'place', 'couple', 'fact', 'idea', 'twist', 'fun', 'novella', 'recipe', 'person', 'feeling', 'fan', 'brother', 'mystery', 'problem', 'other', 'issue', 'past', 'beginning', 'moment', 'hero', 'heroine', 'information', 'mind', 'night', 'chapter', 'father', 'copy', 'mother', 'tale', 'side', 'emotion', 'reason', 'sister', 'kid', 'reading', 'eye', 'Ms.', 'boy', 'writer', 'detail', 'storyline', 'chance', 'style', 'situation', 'money', 'kind', 'type', 'sense', 'home', 'self', 'parent', 'school', 'town', 'head']\n"
     ]
    }
   ],
   "source": [
    "print([w[0] for w in noun_counter])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595d4c3f",
   "metadata": {},
   "source": [
    "Тут все вполне логично с точки зрения содержания. Кажется, часть этих слов тоже имеет смысл включить в итоговый набор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c2499fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_set += ['book', 'story', 'series', 'novel', 'novella', 'tale']\n",
    "core = set(noun_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f05c294a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7b37677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tale', 'ebook', 'collection', 'trilogy', 'memoir', 'book', 'volume', 'ebooks', 'manga', 'series', 'edition', 'thriller', 'novella', 'biography', 'cookbook', 'saga', 'guide', 'story', 'novel'}\n"
     ]
    }
   ],
   "source": [
    "print(core)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abc4cea",
   "metadata": {},
   "source": [
    "#### Векторная модель\n",
    "Перейдем к обучению векторной модели на нашем корпусе. У нас уже есть распаршенные с помощью spacy тексты, осталось привести их к виду текстов (а не списков кортежей с тегами) и передать модели на обучение.\n",
    "\n",
    "НЕ ЗАПУСКАТЬ ОБУЧЕНИЕ МОДЕЛИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea7947",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(lem_texts, window=3,\n",
    "                               min_count=2, seed=seed)\n",
    "model.wv.save('word2vec.wordvectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b35cdf",
   "metadata": {},
   "source": [
    "ЗАПУСКАТЬ ОТСЮДА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3d48df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wv = KeyedVectors.load('word2vec.wordvectors', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eab1f311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('novel', 0.7926753163337708),\n",
       " ('novella', 0.7717196941375732),\n",
       " ('story', 0.7468701004981995),\n",
       " ('series', 0.74058598279953),\n",
       " ('trilogy', 0.6998007297515869),\n",
       " ('installment', 0.6991181969642639),\n",
       " ('volume', 0.6868460774421692),\n",
       " ('ebook', 0.6847478747367859),\n",
       " ('cookbook', 0.6442406177520752),\n",
       " ('episode', 0.6115556359291077)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wv.most_similar('book', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5037671d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('biography', 0.7878738045692444),\n",
       " ('poetry', 0.7064180374145508),\n",
       " ('essay', 0.6857961416244507),\n",
       " ('diary', 0.6478056311607361),\n",
       " ('nonfiction', 0.6450907588005066),\n",
       " ('poet', 0.6251628398895264),\n",
       " ('parable', 0.6183352470397949),\n",
       " ('screenplay', 0.6136636137962341),\n",
       " ('poem', 0.605504035949707),\n",
       " ('literature', 0.5864816904067993)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wv.most_similar('memoir', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3dc546",
   "metadata": {},
   "source": [
    "Кажется, модель неплохо обучилась. Я пробовала использовать готовые эмбеддинги (обученные на твиттере и википедии), но они выдают результаты, не специфичные для нашего корпуса (а для нас это скорее плюс, чем минус).\n",
    "\n",
    "Итак, мы получили набор существительных, которые могут называть товары в нашем датасете, и векторную модель, обученную на отзывах.\n",
    "\n",
    "#### Выделение сущностей из отзывов\n",
    "Попробуем несколько вариантов:\n",
    "* Брать пересечение слов из отзыва со словами core\n",
    "* Выделять ключевые слова и конструкции и выбирать те, в которых есть слова из core\n",
    "* Выделять названия товаров из отзыва как самые близкие к словам из core\n",
    "\n",
    "#### Пересечение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "195bf74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3699935a46b54b46a08f51d4491f0beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/485125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "common_words = []\n",
    "for review in tqdm(lem_texts):\n",
    "    common_words.append(set(review).intersection(core))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a49161c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'novella'} \n",
      " Light, short novella, nothing too deep - Cade and Elliot meet doing trash recycling for community time. One is a raunchy waiter, the other younger and more conservative, and they connect and go on from there. It's actually quite forgettable, but not at all offensive... I rate it B+ but not necessarily a reread and certainly not essential to own (unlike the excellent Jez Morrow's Force of Law - against which all other m/m novellas are judged and found wanting...) \n",
      "\n",
      "{'story'} \n",
      " Have to admit I expected more even though it is a short story. Just fell a little flat. Not my favourite. Sorry \n",
      "\n",
      "{'book'} \n",
      " This is the best to describe this book due to the main characters are from opposite side of the track and comes from two different worlds but in serving community service they meet and find that are so much alike and have so much in common. In the difference they fall in love and build the perfect relationship and learn how to love and care for each other and over look the differences. \n",
      "\n",
      "{'story', 'book'} \n",
      " I just love K.A. Mitchell. This story may be short, but its great! Cade is a pierced, bad boy, a free spirit. Elliot is an uptight, do everything by the book, make no mistakes kind of guy. Until Cade brings out the naughty in him! This is a wonderful opposites attract story. \n",
      "\n",
      "{'story'} \n",
      " What a sweet little story. The virgin meets the wild child. The sex was hot. There's not a lot of emotional depth here but still a cute story with a lot of of sex, \n",
      "\n",
      "{'story', 'book', 'series'} \n",
      " Each and every one of these stories keeps you on the edge of your seat! I like series that intertwine all of the characters from the previous books so there is continuity and history to draw from. I love the strong female characters and how love conquers in the end. Lots of sizzle if you are into that sort of thing. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if len(lem_texts[i]) < 100:\n",
    "        print(common_words[i],\n",
    "              '\\n',\n",
    "              texts[i],\n",
    "              '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23373973",
   "metadata": {},
   "source": [
    "Большая проблема: если человек пишем в отзыве что-то типа \"мне нравятся книги, которые...\". Такие случаи выловить нашим методом невозможно, и кажется, что и векторная модель тут не особенно поможет. Тем не менее подход с моделью более гибкий, т.к. позволяет выбирать слова, специфичные для конкретного отзыва.\n",
    "\n",
    "#### Похожие слова\n",
    "Этот способ очень долгий из-за вычисления близости с каждым словом (даже если считать близость только к слову \"book\"), поэтому я сделала подсчет только для части отзывов, чтобы проверить, что получается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f12e9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english') + ['I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b3e44739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6e9ffcfdbc4002bc8bc9589d9617bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "closest_words = []\n",
    "for review in tqdm(lem_texts[:10000]):\n",
    "    sim_dict = {}\n",
    "    # для каждого уникального слова вычисляем близость\n",
    "    for word in list(set(review) - stops):\n",
    "        if word in model_wv:\n",
    "            sim_dict[word] = model_wv.similarity('book', word)\n",
    "    # берем 5 ближайших слов\n",
    "    closest_words.append(nlargest(5, sim_dict, key=sim_dict.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a1ab49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['novella', 'one', 'time', 'short', 'actually'] \n",
      " Light, short novella, nothing too deep - Cade and Elliot meet doing trash recycling for community time. One is a raunchy waiter, the other younger and more conservative, and they connect and go on from there. It's actually quite forgettable, but not at all offensive... I rate it B+ but not necessarily a reread and certainly not essential to own (unlike the excellent Jez Morrow's Force of Law - against which all other m/m novellas are judged and found wanting...) \n",
      "\n",
      "['story', 'short', 'though', 'expect', 'even'] \n",
      " Have to admit I expected more even though it is a short story. Just fell a little flat. Not my favourite. Sorry \n",
      "\n",
      "['book', 'character', 'world', 'relationship', 'different'] \n",
      " This is the best to describe this book due to the main characters are from opposite side of the track and comes from two different worlds but in serving community service they meet and find that are so much alike and have so much in common. In the difference they fall in love and build the perfect relationship and learn how to love and care for each other and over look the differences. \n",
      "\n",
      "['book', 'story', 'short', 'mistake', 'guy'] \n",
      " I just love K.A. Mitchell. This story may be short, but its great! Cade is a pierced, bad boy, a free spirit. Elliot is an uptight, do everything by the book, make no mistakes kind of guy. Until Cade brings out the naughty in him! This is a wonderful opposites attract story. \n",
      "\n",
      "['story', 'depth', 'child', 'still', 'sex'] \n",
      " What a sweet little story. The virgin meets the wild child. The sex was hot. There's not a lot of emotional depth here but still a cute story with a lot of of sex, \n",
      "\n",
      "['book', 'story', 'series', 'one', 'thing'] \n",
      " Each and every one of these stories keeps you on the edge of your seat! I like series that intertwine all of the characters from the previous books so there is continuity and history to draw from. I love the strong female characters and how love conquers in the end. Lots of sizzle if you are into that sort of thing. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if len(lem_texts[i]) < 100:\n",
    "        print(closest_words[i],\n",
    "              '\\n',\n",
    "              texts[i],\n",
    "              '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d2c9e7",
   "metadata": {},
   "source": [
    "Здесь получается гораздо больше мусора: если не убирать стоп-слова, то они составляют около половины всей выдачи, но и при их удалении выдача не намного чище, поскольку мы требуем всегда выдавать топ-5 ближайших слов. Эта проблема опять сводится к выбору порога и, на мой взгляд, выходит за рамки этого домашнего задания.\n",
    "\n",
    "#### Ключевые слова\n",
    "В д/з 1 лучшим алгоритмом выделения ключевых слов оказался TF-IDF, но, как известно, этот метод не предназначен для работы с корпусами однородных текстов, а именно с таким корпусом мы сейчас имеем дело. На втором месте по качеству оказался TextRank, так что используем его.\n",
    "\n",
    "Сначала выделим ключевые слова, а затем проверим, какие из них входят в core. Это тоже работает очень долго, поэтому проверим на части корпуса..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "05a7e77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beecf5996ed44b43b98662a0c049adac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/485125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "joined_lemmas = [' '.join(text) for text in tqdm(lem_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e1426fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0ae1fb8a5b4c14b51da3616ebdbc6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "textrank_kws = []\n",
    "\n",
    "for text in tqdm(joined_lemmas[:1000]):\n",
    "    kw_list = keywords.keywords(text, language='english',\n",
    "                                ratio=0.5,\n",
    "                                additional_stopwords=stops).split('\\n')\n",
    "    textrank_kws.append(set(kw_list).intersection(core))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "548e5ff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book'}, set(), set(), set(), {'book'}, set(), set(), set(), set(), set()]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textrank_kws[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86537c9c",
   "metadata": {},
   "source": [
    "Отличный способ, я победила эту домашку))\n",
    "\n",
    "Из трех испробованных методов наиболее удачным, как ни странно, оказался самый простой: использование core для выделения упоминаний из отзывов. В дальнейшем можно расширять core разными способами: вручную, просматривая словари синонимов; используя WordNet; повторяя наш алгоритм на новых данных.\n",
    "\n",
    "### Пункт 3: n-граммы с полученными сущностями (1 балл)\n",
    "Поскольку все сущности у нас однословные, то под шаблон \"NE + левый сосед / NE + правый сосед\" подходят только биграммы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42f36322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fff40c4ed74a4b8145359389522966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/485125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lem_texts_lower = [t.lower().split() for t in tqdm(joined_lemmas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c6be5c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cdfa531124c4b6fb27d63804c4ea86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/485125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bigrams = Counter()\n",
    "\n",
    "for text in tqdm(lem_texts_lower):\n",
    "\n",
    "    # отсекаем тексты, где нет ничего подходящего\n",
    "    if not set(text).intersection(core):\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        bigrams.update(list(ngrams(text, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6308098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e38b1a9328c4891b29ad20225fbab05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4230116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "core_bigrams = []\n",
    "for bigr in tqdm(bigrams.most_common()):\n",
    "    if set(bigr[0]).intersection(core):\n",
    "        core_bigrams.append(bigr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b21c9e",
   "metadata": {},
   "source": [
    "### Пункт 4: ранжирование n-грамм\n",
    "#### PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7eb2a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0a78bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_finder = BigramCollocationFinder.from_documents(lem_texts_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd8c28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# корпус большой, так что и фильтр побольше\n",
    "# кстати, он очень влияет, на 5 было много мусора\n",
    "bigram_finder.apply_freq_filter(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9dd08a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_pmi = bigram_finder.score_ngrams(bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae075fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_bigrams(bigrams_with_scores, core_bigrams):\n",
    "    bigrams_no_scores = [bigr[0] for bigr in bigrams_with_scores]\n",
    "    core_bigrams_no_freq = set([bigr[0] for bigr in core_bigrams])\n",
    "    arranged_bigrams = [bigr for bigr in tqdm(bigrams_no_scores)\n",
    "                        if bigr in core_bigrams_no_freq]\n",
    "    return arranged_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0afc2935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142ba27d249d400facbc6a1304f03405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/320707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arranged_by_pmi = arrange_bigrams(bigrams_pmi, core_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "16726f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fairytail', 'saga'),\n",
       " ('omnibus', 'edition'),\n",
       " ('wardstone', 'trilogy'),\n",
       " ('artists', 'trilogy'),\n",
       " ('bloodstone', 'saga'),\n",
       " ('riverside', 'trilogy'),\n",
       " ('seen', 'trilogy'),\n",
       " ('lodestone', 'trilogy'),\n",
       " ('newsflesh', 'trilogy'),\n",
       " ('techno', 'thriller'),\n",
       " ('colter', 'saga'),\n",
       " ('firebird', 'trilogy'),\n",
       " ('enslaved', 'trilogy'),\n",
       " ('255', 'guide'),\n",
       " ('cautionary', 'tale'),\n",
       " ('details', 'ebook'),\n",
       " ('psychological', 'thriller'),\n",
       " ('revise', 'edition'),\n",
       " ('fairy', 'tale'),\n",
       " ('beginners', 'guide')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arranged_by_pmi[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0603d608",
   "metadata": {},
   "source": [
    "С одной стороны, тут есть полезные биграммы с именами собственными; с другой, непонятно, насколько они отражают именно наименования тех товаров, к которым относится отзыв (т.е. я скорее представляю себе отзыв типа \"эта книга фигня, а вот firebird trilogy...\" -- но это моя интуиция, и неясно, обоснованная ли). Ну и, конечно, заметна известная склонность PMI переоценивать редкие слова.\n",
    "\n",
    "#### T-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fed8a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_t = bigram_finder.score_ngrams(bigram_measures.student_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f257d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c8b732632b4dcd854cff2fd8c1633a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/320707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arranged_by_t = arrange_bigrams(bigrams_t, core_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f4d91323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'book'),\n",
       " ('the', 'story'),\n",
       " ('the', 'book'),\n",
       " ('this', 'story'),\n",
       " ('this', 'series'),\n",
       " ('book', 'be'),\n",
       " ('short', 'story'),\n",
       " ('the', 'series'),\n",
       " ('book', 'in'),\n",
       " ('next', 'book'),\n",
       " ('book', 'i'),\n",
       " ('story', 'be'),\n",
       " ('first', 'book'),\n",
       " ('story', 'line'),\n",
       " ('love', 'story'),\n",
       " ('great', 'book'),\n",
       " ('great', 'story'),\n",
       " ('story', 'that'),\n",
       " (\"'s\", 'story'),\n",
       " ('other', 'book')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arranged_by_t[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b78f774",
   "metadata": {},
   "source": [
    "Выдача довольно скучная (помним о склонность t-score переоценивать частотные слова), но, скорее всего, отражающая реальность: все топ-5 биграмм представляются как те, что могут относиться к товарам в отзывах.\n",
    "\n",
    "#### Chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a3b2f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_chi = bigram_finder.score_ngrams(bigram_measures.chi_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc371719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194d32849e114ef7b821ba6111492446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/320707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arranged_by_chi = arrange_bigrams(bigrams_chi, core_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b14f7693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'book'),\n",
       " ('fairy', 'tale'),\n",
       " ('story', 'line'),\n",
       " ('short', 'story'),\n",
       " ('the', 'story'),\n",
       " ('this', 'series'),\n",
       " ('debut', 'novel'),\n",
       " ('length', 'novel'),\n",
       " ('next', 'book'),\n",
       " ('psychological', 'thriller'),\n",
       " ('this', 'story'),\n",
       " ('omnibus', 'edition'),\n",
       " ('kindle', 'edition'),\n",
       " ('artists', 'trilogy'),\n",
       " ('first', 'book'),\n",
       " ('romance', 'novel'),\n",
       " ('cautionary', 'tale'),\n",
       " ('fairytail', 'saga'),\n",
       " ('second', 'book'),\n",
       " ('the', 'book')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arranged_by_chi[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44a23f",
   "metadata": {},
   "source": [
    "Чем-то похоже на то, что у t-score: здесь есть всякие this book, this series, this story, то есть как раз то, что мы хотим видеть в выдаче. Под конец появляются сущности, также встречающиеся в топе PMI. Как ни странно, кажется, что t-score справляется лучше: хоть он и переоценивает частотные слова, его выдача лучше соотносится с наименованиями товаров в отзывах (по крайней мере, в моем воображении).\n",
    "\n",
    "Попробуем взять топ-100 биграмм в рейтингах t-score и chi-square и их пересечение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0d1a573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_and_chi = arranged_by_t[0:100] + arranged_by_chi[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1d1a2cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_t_and_chi = []\n",
    "for bigram in Counter(t_and_chi).most_common():\n",
    "    if bigram[-1] < 2:\n",
    "        break\n",
    "    else:\n",
    "        bigram_str = ''\n",
    "        for word in bigram[0]:\n",
    "            bigram_str += ' '\n",
    "            bigram_str += word\n",
    "        if not re.search(r'[^a-z0-9\\s]', bigram_str):\n",
    "            top_t_and_chi.append(bigram_str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7ebd70e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_t_and_chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "855962fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this book', 'the story', 'the book', 'this story', 'this series', 'book be', 'short story', 'the series', 'book in', 'next book', 'book i', 'story be', 'first book', 'story line', 'love story', 'great book', 'great story', 'story that', 'other book', 'good book', 'second book', 'series i', 'book by', 'story about', 'series and', 'good story', 'these book', 'this novella', 'this novel', 'book 2', 'book down', 'book 1', 'romance novel', 'previous book', 'third book', 'tale of', 'collection of', 'book 3', 'whole series', 'fairy tale', 'wonderful story', 'new series', 'length novel', 'entire series', 'entire book', 'cute story', 'story itself', 'this ebook', 'story flow']\n"
     ]
    }
   ],
   "source": [
    "print(top_t_and_chi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127c010e",
   "metadata": {},
   "source": [
    "Получается довольно много правильного и полезного. В принципе, можно использовать обе метрики, но я боюсь сделать логическую ошибку, пытаясь их объединить. Можно просто для каждого товара взять топ-n и их пересечение, но хочется учитывать не просто факт вхождения биграммы в топ, но и ее позицию в нем, и вот это я уже плохо себе представляю, как реализовывать. Наверное, можно нормализовать значения каждого типа метрик, сложить и ранжировать, а затем взять топ-n, но я не успею попробовать и понять, не ерунду ли предложила :(\n",
    "\n",
    "#### Группировка биграмм по NE (1 балл)\n",
    "В итоге я выбрала метрику t-score, потому что она высоко ранжирует хоть и базовые, зато с большой вероятностью подходящие сущности. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d39a3bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92978bbf3f124f41a9c1d71188c89882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "core_list = list(core)\n",
    "core_collocations = {}\n",
    "\n",
    "for word in tqdm(core_list):\n",
    "    core_collocations[word] = []\n",
    "    # будем записывать в том порядке,\n",
    "    # которые предложил t-score\n",
    "    for bigram in arranged_by_t:\n",
    "        if word in bigram:\n",
    "            bigram_str = ' '.join(str(w) for w in bigram)\n",
    "            if not re.search(r'[^a-z0-9\\s]', bigram_str):\n",
    "                core_collocations[word].append(bigram_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5d07ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book \n",
      "---\n",
      "this book\n",
      "the book\n",
      "book be\n",
      "book in\n",
      "next book \n",
      "\n",
      "series \n",
      "---\n",
      "this series\n",
      "the series\n",
      "series i\n",
      "series and\n",
      "a series \n",
      "\n",
      "story \n",
      "---\n",
      "the story\n",
      "this story\n",
      "short story\n",
      "story be\n",
      "story line \n",
      "\n",
      "tale \n",
      "---\n",
      "tale of\n",
      "fairy tale\n",
      "this tale\n",
      "tale that\n",
      "the tale \n",
      "\n",
      "guide \n",
      "---\n",
      "guide to\n",
      "this guide\n",
      "guide for\n",
      "great guide\n",
      "guide on \n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_results = ['book', 'series', 'story', 'tale', 'guide']\n",
    "for word in show_results:\n",
    "    print(word, '\\n---')\n",
    "    print('\\n'.join(core_collocations[word][0:5]), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93855152",
   "metadata": {},
   "source": [
    "Получилось довольно неплохо! Интересно, каких результатов можно было бы добиться, объединив метрики предложенным выше способом (или каким-то другим, принятым среди компьютерных лингвистов, которые уже закончили бакалавриат...).\n",
    "\n",
    "Из минусов: кажется, мы не очень-то выделяем имена собственные. Две причины, почему это не критично: 1) они на самом деле есть в топе t-score, просто не в топ-5, а где-то в топ-15-20; 2) специфика датасета: имена собственные здесь вряд ли будут отражать собственно тот товар, на который пишется отзыв. Больше похоже, что они будут отсылать к каким-то сущностям из самой книги, или к другим книгам серии, или книгам того же автора/жанра, и т.д.\n",
    "\n",
    "#### Бонус: объединение синонимов\n",
    "Поскольку у меня не остается времени на реализацию, то на бонус я не претендую, просто выскажу свою идею. Для объединения синонимичных употреблений можно попробовать кластеризацию, основанную на векторном представлении слов (у нас как раз есть обученная на отзывах модель). Например, создать векторные представления товаров на основе их названий и кластеризовать их (правда, кажется, что название самого произведения нас может сбить, оно может быть совершенно произвольным; но для случая с часами этот способ должен подойти).\n",
    "\n",
    "И еще про то, как можно улучшить качество: кажется, имеет смысл использовать не леммы, а леммы + части речи (склеив их через нижнее подчеркивание). Это помогло бы бороться со случаями типа read (сущ.: it's a great read) и потенциально улучшило бы работу с векторной моделью. Еще можно доработать алгоритмы, учитывающие ключевые слова, и выделять не только уни-, но и n-граммы, а затем брать те, в которые входит одно из core-слов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
